<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>深入理解 Kubernetes 概述</title>
      <link href="/2020/05/21/k8s01/"/>
      <url>/2020/05/21/k8s01/</url>
      
        <content type="html"><![CDATA[<h1 id="Kubernetes-架构设计"><a href="#Kubernetes-架构设计" class="headerlink" title="Kubernetes 架构设计"></a>Kubernetes 架构设计</h1><p><img src="/images/2020/Kubernetes-architecture.png" alt=""></p><h2 id="Kubernetes-流程"><a href="#Kubernetes-流程" class="headerlink" title="Kubernetes 流程"></a>Kubernetes 流程</h2><p><img src="/images/2020/what-happens-when-k8s.png" alt=""></p><h2 id="Kubernetes-核心组件"><a href="#Kubernetes-核心组件" class="headerlink" title="Kubernetes 核心组件"></a>Kubernetes 核心组件</h2><h3 id="Kubectl"><a href="#Kubectl" class="headerlink" title="Kubectl"></a>Kubectl</h3><p>kubectl 是用户与 Kubernetes 交互的命令行工具。用户使用 kubectl 工具调用 Apiserver 的接口来与 Kubernetes服务进行交互。</p><p>更多 kubectl 信息请参考：<a href="k8s2.md">深入理解 Kubernetes 之 Kubectl</a></p><h3 id="Kube-API-server"><a href="#Kube-API-server" class="headerlink" title="Kube API server"></a>Kube API server</h3><p>Kubernetes API server 为 api 对象验证并配置数据，包括 pods、 services、 replicationcontrollers 和其它 api 对象。API Server 提供 REST 操作和到集群共享状态的前端，所有其他组件通过它进行交互，是整个系统的数据总线和数据中心。</p><p>Kubernetes 中的其它组件都不会和 etcd 进行交互，只有 API Server 可以和 etcd 进行交互,API Server  具有如下功能：</p><ul><li>整个集群管理的 API 接口：所有对集群进行的查询和管理都是通过 API 进行</li><li>集群内部各个模块之间通信的枢纽：所有模块之间并不会互相调用，而是通过和 API Serve r打交道完成这部分的工作</li><li>集群的安全控制: API Server 提供的验证和授权和访问控制保证了整个集群的安全</li></ul><p>更多 Kube API server 信息请参考：<a href="k8s3.md">深入理解 Kubernetes 之 Kube API server</a></p><h3 id="Controller-manager"><a href="#Controller-manager" class="headerlink" title="Controller manager"></a>Controller manager</h3><p>Controller Manager 就是集群内部的管理控制中心，由负责不同资源的多个 Controller 构成，共同负责集群内的 Node、Pod 等所有资源的管理，比如当通过 Deployment 创建的某个 Pod 发生异常退出时，RS Controller 便会接受并处理该退出事件，并创建新的 Pod 来维持预期副本数。</p><p>几乎每种特定资源都有特定的 Controller 维护管理以保持预期状态，而 Controller Manager 的职责便是把所有的 Controller 聚合起来：</p><ol><li>提供基础设施降低 Controller 的实现复杂度</li><li>启动和维持 Controller 的正常运行</li></ol><p>可以这么说，Controller 保证集群内的资源保持预期状态，而 Controller Manager 保证了 Controller 保持在预期状态。</p><p>更多 Controller manager 信息请参考：<a href="k8s4.md">深入理解 Kubernetes 之 Controller manager</a></p><h3 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h3><p>调度是 Kubernetes 集群中进行容器编排工作最重要的一环，在 Kubernetes中，Controller manager 负责创建Pod，Kubelet 负责执行 Pod，而 Scheduler 就是负责安排 Pod 到具体的 Node，它通过 API Server 提供的接口监听 Pod 任务列表，获取待调度 pod，然后根据一系列的预选策略和优选策略给各个 Node 节点打分，然后将Pod 发送到得分最高的 Node 节点上，由 kubelet 负责执行具体的任务内容。</p><p>更多 Scheduler  信息请参考：<a href="k8s5.md">深入理解 Kubernetes 之 Scheduler </a></p><h3 id="Kubelet"><a href="#Kubelet" class="headerlink" title="Kubelet"></a>Kubelet</h3><p>每个Node都会启动一个kubelet，主要作用有：</p><ul><li><p>Node管理</p><ul><li><p>注册节点信息；</p></li><li><p>通过 cAdvisor 监控容器和节点的资源；</p></li><li><p>定期向 API server 汇报本节点资源消耗情况</p></li></ul></li><li><p>Pod管理</p><ul><li>所有非通过 API server 方式创建的 Pod 叫 Static Pod，这里我们讨论的都是通过 API server 创建的普通Pod。kubelet 通过 API server 监听 etcd，所有针对 Pod 的操作都会被监听到，如果其中有涉及到本节点的 Pod，则按照要求进行创建、修改、删除等操作。</li></ul></li><li><p>容器健康检查</p><p>kubelet通过两类探针检查容器的状态：</p><ul><li><p>LivenessProbe：判断一个容器是否健康，如果不健康则会删除这个容器，并按照 restartPolicy 看是否重启这个容器。实现的方式有 ExecAction（在容器内部执行一个命令）、TCPSocketAction（如果端口可以被访问，则健康）、HttpGetAction（如果返回200则健康）。</p></li><li><p>ReadinessProbe：用于判断容器是否启动完全。如果返回的是失败，则 Endpoint Controller 会将这个Pod 的 Endpoint从Service 的 Endpoint 列表中删除。也就是，不会有请求转发给它。</p></li></ul></li></ul><p>更多 Kubelet信息请参考：<a href="k8s6.md">深入理解 Kubernetes 之 Kubelet</a></p><h3 id="Kube-proxy"><a href="#Kube-proxy" class="headerlink" title="Kube proxy"></a>Kube proxy</h3><p>每个 Node 上都运行着一个 kube-proxy 进程，它在本地建立一个 SocketServer 接收和转发请求，可以看作是Service 的透明代理和负载均衡器，负载均衡策略模式是 Round Robin。也可以设置会话保持，策略使用的是 ClientIP，将同一个 ClientIP 的请求转发同一个 Endpoint 上。</p><p>Service 的 Cluster IP 和 NodePort 等概念都是 kube-proxy 服务通过 iptables 的 NAT 转换实现，iptables 机制针对的是 kube-proxy 监听的端口，所以每个 Node 上都要有 kube-proxy。</p><p>更多 Kube proxy 信息请参考：<a href="k8s7.md">深入理解 Kubernetes 之 Kube proxy</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 Libra</title>
      <link href="/2020/05/20/libra/"/>
      <url>/2020/05/20/libra/</url>
      
        <content type="html"><![CDATA[<h3 id="1-共识"><a href="#1-共识" class="headerlink" title="1. 共识"></a>1. 共识</h3><p>区块链技术中，共识算法是其中核心的一个组成部分。它包含两层含义：</p><ol><li>多个节点对某个数据达成一致共识。</li><li>多个节点对多个数据的顺序达成一致共识。</li></ol><p>共识算法主要用在以下三种场景：</p><ul><li>私链<ul><li>私链的共识算法即传统分布式系统里的共识算法，比如 zookeeper 的 zab 协议，就是类 paxos 算法的一种。私链一般不考虑集群中存在作恶节点，只考虑因为系统或者网络原因导致的故障节点。</li></ul></li><li>联盟链<ul><li>联盟链代表项目是 Fabric，它使用的就是 PBFT(实用拜占庭) 算法。联盟链除了需要考虑集群中存在故障节点，还需要考虑集群中存在作恶节点。对于联盟链，每个新加入的节点都是需要验证和审核。</li></ul></li><li>公链<ul><li>公链不仅需要考虑网络中存在故障节点，还需要考虑作恶节点，这一点和联盟链是类似的。和联盟链最大的区别就是，公链中的节点可以很自由的加入或者退出，不需要严格的验证和审核。</li></ul></li></ul><h3 id="2-通讯模型"><a href="#2-通讯模型" class="headerlink" title="2. 通讯模型"></a>2. 通讯模型</h3><p>分布式系统首先要明确其前置的<code>通讯模型</code>（也称为<code>时间模型</code>）的约定。比较常见的有<strong>同步网络模型</strong>、<strong>异步网络模型</strong>和<strong>部分同步网络模型</strong>。</p><h4 id="2-1-同步网络模型"><a href="#2-1-同步网络模型" class="headerlink" title="2.1 同步网络模型"></a><strong>2.1 同步网络模型</strong></h4><p>节点所发出的消息，在一个确定的时间内，肯定会到达目标节点。</p><p>在同步网络模型中：</p><ol><li>进程间的消息通讯、传输延时有界。认为通讯耗时是有确定范围的；</li><li>每个进程的处理速度是确定的。我们可以确切知道进程中每步算法的耗时。</li></ol><p>我们可以推导出：</p><ul><li>每个进程间的时钟是同步的，因为前面的定义<strong>1</strong>、<strong>2</strong>，所以我们可以使用通讯来同步各个机器上的时钟，使得各个机器的时钟误差在 ΔT 内。</li><li>如果一个请求的应答超过 RTT+ ΔT 请求处理耗时，则可以判定对端异常。</li></ul><p><code>同步网络模型</code>使用起来最简单，是理想的网络模型，在实际环境中并不存在。</p><h4 id="2-2-异步网络模型"><a href="#2-2-异步网络模型" class="headerlink" title="2.2 异步网络模型"></a><strong>2.2 异步网络模型</strong></h4><p>节点所发出的消息，不能确定一定会到达目标节点。</p><p>在<code>异步网络模型</code>中，我们引用 <strong>FLP 不可能性</strong>[^6]中的定义：</p><ol><li>进程间的消息通讯、传输延时没有上界；</li><li>每个进程的处理速度是不确定的；</li><li>每个机器上没有同步时钟（即不存在原子钟这种东西），时间流逝速度可能也不同。</li></ol><p>因此我们可以推导出：</p><ul><li>各个机器上的时钟没有可参考性，因为根据上面 3 每个机器不能自发保持时间的一致性，并且因为1、2，机器时间也无法同步时钟在一个有界的误差之内。所以依赖超时机制的算法并不可用。</li><li>因为1、2，当一个请求在本地时钟上超时后，我们无法判断这个请求是否是因为对端异常造成的。这是一个经典的<strong>两军问题</strong><a href="https://en.wikipedia.org/wiki/Two_Generals%27_Problem](https://en.wikipedia.org/wiki/Two_Generals' target=" _blank"="" rel="noopener" _problem"="">^1</a>场景，故，我们无法对其他实例进行故障探测。</li></ul><p>从定义中 3，我们引出两个概念，但是这两个概念原本是集成电路[^7][^8]中的概念，但是我们在分布式系统中重新扩展一下：</p><ul><li><code>clock drift(时钟漂移)</code>：相关节点上的时钟以不同的速率运行。在 P1 节点上经过 ΔT1 的同时，P2 节点经过了ΔT2，但是 ΔT1≠ΔT2。</li><li><code>clock skew(时钟偏移)</code>：相关节点都引用了同一个时间源（比如通过 NTP 服务），但是由于这个时间源将授时信号同步不同节点时的耗时不同（比如网络传输耗时），造成同一时刻不同节点间产生了时间差。这是一个比<code>clock drift(时钟漂移)</code>更加严格的要求，因为如果一个系统内部的 TSkew 存在上界TShewMax ，那一定能通过不断的校时、保持时钟同步，使得 TDrift 保持在 TShewMax 以内。</li></ul><p>异步网络模型是一个最理想的<strong>最差</strong>网络模型，但是其复杂度又远超我们实际情形。</p><h4 id="2-3-部分同步网络模型"><a href="#2-3-部分同步网络模型" class="headerlink" title="2.3 部分同步网络模型"></a><strong>2.3 部分同步网络模型</strong></h4><p>节点发出的消息，虽然会有延迟，但是最终会到达目标节点。</p><p>我们现实中遇见的网络模型通常介于同步网络模型和异步网络模型两者之间。因为在我们所知的大部分系统，在大部分时间内：</p><ul><li>进程间的消息通讯、传输延时是有上界的；只有在网络过载、网络分区故障时，才没有上界；</li><li>每个进程的处理速度是确定的；只有在发生 GC 、磁盘 IO 阻塞等异常情况时，每个进程的处理速度才不可确定。</li><li>每个机器上的时钟我们可以认为是基本同步的，比如我们可以使用 NTP[^9]来同步机器时间，而且多数机器上有独立的时钟芯片[^10]，我们也可以粗略认为各个机器上时间流逝的速度是相同的。但是严格要求时序的系统除外。</li></ul><h3 id="3-Raft-算法"><a href="#3-Raft-算法" class="headerlink" title="3. Raft 算法"></a>3. Raft 算法</h3><p>raft 中节点有三种状态：</p><ul><li>Follower （跟随者）  被动的只是响应来自领导者和候选人的请求 </li><li>Candidate （候选人）被选出一个新的Leader </li><li>Leader（领导者）  处理所有来自客户端的请求</li></ul><p>集群中的一个节点在某一时刻只能是这三种状态的其中一种，这三种状态是可以随着时间和条件的变化而互相转换的。</p><p>raft 算法主要有两个过程：</p><ul><li>领导者选举</li><li>日志复制<ul><li>记录日志</li><li>提交数据 </li></ul></li></ul><p>raft 算法支持最大的容错故障节点 (n-1)/2，其中 n 为集群中总的节点数量。</p><blockquote><p>raft 算法只支持容错故障节点，假设集群总节点数为 n，故障节点为 f，根据小数服从多数的原则，集群里正常节点只需要比 f 个节点再多一个节点，即 f+1个节点，正确节点的数量就会比故障节点数量多，那么集群就能达成共识。因此 raft 算法支持的最大容错节点数量是 (n-1)/2。</p></blockquote><p>可参考<a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">动画</a>理解</p><h4 id="3-1-算法复杂度"><a href="#3-1-算法复杂度" class="headerlink" title="3.1 算法复杂度"></a>3.1 算法复杂度</h4><p>Raft 算法核心是日志复制这个过程，这个过程分两个阶段：一个是日志记录，一个是提交数据。两个过程都只需要领导者发送消息给跟随者节点，跟随者节点返回消息给领导者节点即可完成，跟随者节点之间是无需沟通的。所以如果集群总节点数为 n，对于日志记录阶段，通信次数为 n-1，对于提交数据阶段，通信次数也为 n-1，总通信次数为 2n-2，因此 raft 算法复杂度为O(n)。</p><h3 id="4-两军问题"><a href="#4-两军问题" class="headerlink" title="4. 两军问题"></a>4. 两军问题</h3><p>两军问题<a href="https://en.wikipedia.org/wiki/Two_Generals%27_Problem](https://en.wikipedia.org/wiki/Two_Generals' target=" _blank"="" rel="noopener" _problem"="">^1</a>，又称为“两军悖论”，是计算机通信领域的一个思想实验，主要用来描述在一个不可靠的通信链上试图通过通信达成一致是存在缺陷与困难的，适用于任何可能通信失败情况下的两点通信，两军问题被证明无解。如果通信信道是可靠的，我们只需三次握手就可以解决问题，你将消息发给战友，战友确认回复，你再确认收到回复，经过这三次握手，基本就可以发起进攻，但是两军问题面临的通信通道是不可靠的，无论多少次握手也无法保证最后一次通信准确送达，最后一次通信的发送方就会一直面临着冒着失败风险的行动。</p><h3 id="5-拜占庭将军问题"><a href="#5-拜占庭将军问题" class="headerlink" title="5. 拜占庭将军问题"></a>5. 拜占庭将军问题</h3><p>拜占庭将军问题是一个共识问题: 首先由 Leslie Lamport 与另外两人在1982年提出，被称为 The Byzantine Generals Problem<a href="https://dl.acm.org/citation.cfm%3Fid%3D357176" target="_blank" rel="noopener">^2</a>或者 Byzantine Failure。核心描述是军中可能有叛徒，却要保证进攻一致，由此引申到计算领域，发展成了一种容错理论，即拜占庭容错（BFT，Byzantine Fault Tolerance）。简单来说，拜占庭容错（BFT）是能够抵抗拜占庭将军问题导致的一系列失败的系统属性。 这意味着即使某些节点出现故障或恶意行为，拜占庭容错系统也能够继续运行。</p><p>拜占庭将军的问题有多种可能的解决方案，因此，有多种方法可以构建拜占庭容错系统。同样地，区块链有各种不同的方法来实现拜占庭容错，这就是我们说的共识算法。</p><h4 id="5-1-问题描述"><a href="#5-1-问题描述" class="headerlink" title="5.1 问题描述"></a>5.1 问题描述</h4><p>拜占庭帝国想要进攻一个强大的敌人，为此派出了10支军队去包围这个敌人。这个敌人虽不比拜占庭帝国，但也足以抵御5支常规拜占庭军队的同时袭击。基于一些原因，这10支军队不能集合在一起单点突破，必须在分开的包围状态下同时攻击。他们任一支军队单独进攻都毫无胜算，除非有至少6支军队同时袭击才能攻下敌国。他们分散在敌国的四周，依靠通信兵相互通信来协商进攻意向及进攻时间。困扰这些将军的问题是，他们不确定他们中是否有叛徒，叛徒可能擅自变更进攻意向或者进攻时间。在这种状态下，拜占庭将军们能否找到一种分布式的协议来让他们能够远程协商，从而赢取战斗？这就是著名的拜占庭将军问题。</p><p>需要明确，拜占庭将军问题中并不去考虑通信兵是否会被截获或无法传达信息等问题，即消息传递的信道绝无问。</p><p>Lamport已经证明了<strong>在消息可能丢失的不可靠信道上试图通过消息传递的方式达到一致性是不可能的</strong>。所以，在研究拜占庭将军问题的时候，我们已经假定了信道是没有问题的，并在这个前提下，去做一致性和容错性相关研究。如果需要考虑信道是有问题的，这涉及到了另一个相关问题：<strong>两军问题</strong>。</p><p>拜占庭失效指一方向另一方发送消息，另一方没有收到，或者收到了错误的信息的情形。在容错的分布式计算中，拜占庭失效可以是分布式系统中算法执行过程中的任意一个错误。</p><p>Lamport提出并论证了口头算法和书面算法两种解决方法。</p><h4 id="5-2-口头协议"><a href="#5-2-口头协议" class="headerlink" title="5.2 口头协议"></a>5.2 口头协议</h4><p>首先，我们明确什么是口头协议。我们将满足以下三个条件的方式称为口头协议：</p><pre><code> (1) 每个被发送的消息都能够被正确的投递 (2) 信息接收者知道是谁发送的消息 (3) 能够知道缺少的消息</code></pre><p>简而言之，信道绝对可信，且消息来源可知。但要注意的是，口头协议并不会告知消息的上一个来源是谁。</p><p>Lamport 论证得出结论：采用口头协议，若叛徒数少于 1/3，则拜占庭将军问题可解。也就是说，若叛徒数为m，当将军总数n至少为 3m+1 时，问题可解。</p><h4 id="5-3-书面协议"><a href="#5-3-书面协议" class="headerlink" title="5.3 书面协议"></a>5.3 书面协议</h4><p>揭示了口头协议的缺点是消息不能追本溯源，这使得口头协议必须在四模冗余的情况下才能保证正确。由此引入了书面协议。</p><p>在口头协议的三个条件之上，再添加一个条件，使之成为书面协议。</p><pre><code> （a）签名不可伪造，一旦被篡改即可发现，而叛徒的签名可被其他叛徒伪造； （b）任何人都可以验证签名的可靠性。  </code></pre><p>可以论证：对于任意m，最多只有m个背叛者情况下，算法SM(m)能解决拜占庭将军问题。</p><p>书面协议的本质就是引入了签名系统，这使得所有消息都可追本溯源。这一优势，大大节省了成本，他化解了口头协议中1/3要求，只要采用了书面协议，忠诚的将军就可以达到一致。</p><h3 id="6-实用拜占庭容错（PBFT）"><a href="#6-实用拜占庭容错（PBFT）" class="headerlink" title="6. 实用拜占庭容错（PBFT）"></a>6. 实用拜占庭容错（PBFT）</h3><p>实用拜占庭容错协议<a href="http://pmg.csail.mit.edu/papers/osdi99.pdf" target="_blank" rel="noopener">^3</a>（PBFT，Practical Byzantine Fault Tolerance）是Miguel Castro (卡斯特罗)和Barbara Liskov（利斯科夫）在1999年提出来的，解决了原始拜占庭容错算法效率不高的问题，将算法复杂度由指数级降低到多项式级，使得拜占庭容错算法在实际系统应用中变得可行。</p><p>PBFT 是一个具有二轮投票的三阶段协议，每个视图(View)都会有一个特定的节点作为领导节点(Primary/Leader)，负责通知所有节点进入投票流程。各节点则会经历 Pre-prepare/Prepare/Commit 这三个阶段，并依据接收的讯息决定是否投票/进入下一阶段，每个节点投完票后将讯息发给所有其他的节点。</p><p>若个节点在两阶段投票之后取得多数共识，则各节点可以更新本机的状态，结束这一回合。视图变换(view change)仅当多数节点发起时执行，当目前的领导节点并未正常执行任务时，这可以替换当前的领导节点，保证协议正常运作。</p><p>PBFT 是一种状态机副本复制算法，即服务作为状态机进行建模，状态机在分布式系统的不同节点进行副本复制。每个状态机的副本都保存了服务的状态，同时也实现了服务的操作。将所有的副本组成的集合使用大写字母 R 表示，使用 0 到 R 减1的整数表示每一个副本。为了描述方便，假设 R=3f+1，这里 f 是有可能失效的副本的最大个数。尽管可以存在多于 3f+1 个副本，但是额外的副本除了降低性能之外不能提高可靠性。</p><p>主节点由公式<code>p = v mod R</code>计算得到，这里 v 是视图编号，p 是副本编号，R 是副本集合的个数。当主节点失效的时候就需要启动视图更换（view change）过程。Viewstamped Replication 算法和 Paxos 算法就是使用类似方法解决良性容错的。</p><p>每个副本节点的状态都包含了服务的整体状态，副本节点上的<strong>消息日志(message log)</strong>包含了该副本节点<strong>接受(accepted)</strong>的消息，并且使用一个整数表示副本节点的当前视图编号。</p><blockquote><p>为什么节点数需要大于 3f+1 </p><p>因为最坏的情况是：f 个节点是有问题的，由于到达顺序的问题，有可能 f 个有问题的节点比正常的 f 个节点先返回消息，又要保证收到的正常的节点比有问题的节点多，所以需要满足n-f-f&gt;f =&gt; n&gt;3f，所以至少3f+1个节点。</p><img src="/images/2019/pbft_1.png"></blockquote><h4 id="6-1-系统模型"><a href="#6-1-系统模型" class="headerlink" title="6.1 系统模型"></a>6.1 系统模型</h4><p>一组节点构成状态机复制系统，一个节点作为主节点（privary），其他节点作为备份节点(back-ups)。某个节点作为主节点时，这称为系统的一个 view。当节点出了问题，就进行 view 更新，切换到下一个节点担任主节点。主节点更替不需要选举过程，而是采用 round-robin 方式。</p><p>在系统的主节点接收 client 发来的请求，并产生 pre-prepare 消息，进入共识流程。</p><p>我们需要系统满足如下两个条件：</p><ul><li>在一个给定状态上的操作， 产生一样的执行结果</li><li>每个节点都有一样的起始状态</li></ul><p>要保证 non-fault 节点对于执行请求的<strong>全局顺序</strong>达成一致。</p><h4 id="6-2-安全性-safety-活性-liveness"><a href="#6-2-安全性-safety-活性-liveness" class="headerlink" title="6.2 安全性(safety) / 活性(liveness)"></a>6.2 安全性(safety) / 活性(liveness)</h4><ul><li><strong>safety</strong>: 坏的事情不会发生，即共识系统不能产生错误的结果，比如一部分节点说yes，另一部分说no。在区块链的语义下，指的是不会分叉。</li><li><strong>liveness</strong>: 好的事情一定会发生，即系统一直有回应，在区块链的语义下，指的是共识会持续进行，不会卡住。假如一个区块链系统的共识卡在了某个高度，那么新的交易是没有回应的，也就是不满 liveness。</li></ul><h4 id="6-3-PBFT算法的步骤"><a href="#6-3-PBFT算法的步骤" class="headerlink" title="6.3 PBFT算法的步骤"></a>6.3 PBFT算法的步骤</h4><ol><li>取一个节点作为主节点，其他的节点作为备份；</li><li>客户端向主节点发送使用服务操作的请求；</li><li>主节点通过广播将请求发送给其他节点；</li><li>所有节点执行请求并将结果发回客户端；</li><li>客户端需要等待 f+1 个不同节点发回相同的结果，作为整个操作的最终结果。</li></ol><p>同所有的状态机副本复制技术一样，PBFT 对每个节点提出了两个限定条件：</p><ol><li>所有节点必须是确定性的。也就是说，在给定状态和参数相同的情况下，操作执行的结果必须相同；</li><li>所有节点必须从相同的状态开始执行。</li></ol><p>这两个限定条件下，即使失效的节点存在，PBFT 算法对所有非失效节点的请求执行总顺序达成一致，从而保证安全性。</p><pre class=" language-假设节点总数为3f+1，f为拜赞庭错误节点："><code class="language-假设节点总数为3f+1，f为拜赞庭错误节点：">1. 当节点发现 leader 作恶时，通过算法选举其他的 replica 为 leader。2. leader 通过 pre-prepare 消息把它选择的 value 广播给其他 replica 节点，其他的 replica 节点如果接受则发送 prepare，如果失败则不发送。3. 一旦2f个节点接受 prepare 消息，则节点发送 commit 消息。4. 当2f+1个节点接受 commit 消息后，代表该 value 值被确定。</code></pre><p>如下图表示了4个节点，0为leader，同时节点3为fault节点，该节点不响应和发出任何消息，C为客户端。最终节点状态达到commited时，表示该轮共识成功达成。</p><img src="/images/2019/pbft.png"><h4 id="6-4-客户端C"><a href="#6-4-客户端C" class="headerlink" title="6.4 客户端C"></a>6.4 客户端C</h4><p>客户端c向主节点发送<code>&lt;REQUEST,o,t,c&gt;</code>请求执行状态机操作o，这里时间戳t用来保证客户端请求只会执行一次。客户端c发出请求的时间戳是全序排列的，后续发出的请求比早先发出的请求拥有更高的时间戳。例如，请求发起时的本地时钟值可以作为时间戳。</p><p>每个由副本节点发给客户端的消息都包含了当前的视图编号，使得客户端能够跟踪视图编号，从而进一步推算出当前主节点的编号。客户端通过点对点消息向它自己认为的主节点发送请求，然后主节点自动将该请求向所有备份节点进行广播。</p><p>副本发给客户端的响应为<code>&lt;REPLY,v,t,c,i,r&gt;</code>，v是视图编号，t是时间戳，i是副本的编号，r是请求执行的结果。</p><p>客户端等待f+1个从不同副本得到的同样响应，同样响应需要保证签名正确，并且具有同样的时间戳t和执行结果r。这样客户端才能把r作为正确的执行结果，因为失效的副本节点不超过f个，所以f+1个副本的一致响应必定能够保证结果是正确有效的。</p><p>如果客户端没有在有限时间内收到回复，请求将向所有副本节点进行广播。如果请求已经在副本节点处理过了，副本就向客户端重发一遍执行结果。如果请求没有在副本节点处理过，该副本节点将把请求转发给主节点。如果主节点没有将该请求进行广播，那么就有认为主节点失效，如果有足够多的副本节点认为主节点失效，则会触发一次视图变更。</p><p>本文假设客户端会等待上一个请求完成才会发起下一个请求，但是只要能够保证请求顺序，可以允许请求是异步的。</p><h4 id="6-5-预准备-pre-prepare"><a href="#6-5-预准备-pre-prepare" class="headerlink" title="6.5 预准备(pre-prepare)"></a>6.5 预准备(pre-prepare)</h4><p>在预准备阶段，主节点分配一个序列号 n 给收到的请求，然后向所有节点群发预准备消息，预准备消息的格式为<code>&lt;&lt;PRE-PREPARE,v,n,d&gt;,m&gt;</code>，这里 v 是视图编号，m 是客户端发送的请求消息，d 是请求消息 m 的摘要。</p><p>请求本身是不包含在预准备的消息里面的，这样就能使预准备消息足够小，因为<strong>预准备消息的目的是作为一种证明，确定该请求是在视图 v 中被赋予了序号n，从而在视图变更的过程中可以追索</strong>。另外一个层面，将“请求排序协议”和“请求传输协议”进行解耦，有利于对消息传输的效率进行深度优化。</p><p>只有满足以下条件，各个备份节点才会接受一个预准备消息：</p><ol><li>请求和预准备消息的签名正确，并且 d 与 m 的摘要一致。</li><li>当前视图编号是 v。</li><li>该备份节点从未在视图 v 中接受过序号为 n 但是摘要 d 不同的消息 m。</li><li>预准备消息的序号 n 必须在水线（watermark）上下限 h 和 H 之间。</li></ol><p>水线存在的意义在于防止一个失效节点使用一个很大的序号消耗序号空间。</p><h4 id="6-6-准备-prepare"><a href="#6-6-准备-prepare" class="headerlink" title="6.6 准备(prepare)"></a>6.6 准备(prepare)</h4><p>如果备份节点i接受了预准备消息<code>&lt;&lt;PRE-PREPARE,v,n,d&gt;,m&gt;</code>，则进入准备阶段。在准备阶段的同时，该节点向所有副本节点发送准备消息<code>&lt;PREPARE,v,n,d,i&gt;</code>，并且将预准备消息和准备消息写入自己的消息日志。如果看预准备消息不顺眼，就什么都不做。</p><p>包括主节点在内的所有副本节点在收到准备消息之后，对消息的签名是否正确，视图编号是否一致，以及消息序号是否满足水线限制这三个条件进行验证，如果验证通过则把这个准备消息写入消息日志中。</p><p>我们定义准备阶段完成的标志为副本节点i将<code>(m,v,n,i)</code>记入其消息日志，其中 m 是请求内容，预准备消息 m在视图 v 中的编号 n，以及 2f 个从不同副本节点收到的与预准备消息一致的准备消息。每个副本节点验证预准备和准备消息的一致性主要检查：视图编号 v 、消息序号 n 和摘要 d。</p><p>预准备阶段和准备阶段确保所有正常节点对同一个视图中的请求序号达成一致。接下去是对这个结论的形式化证明：如果 <code>prepared(m,v,n,i)</code> 为真，则<code>prepared(m',v,n,j)</code>必不成立，这就意味着至少 f+1 个正常节点在视图 v 的预准备或者准备阶段发送了序号为 n 的消息 m。</p><h4 id="6-7-确认-commit"><a href="#6-7-确认-commit" class="headerlink" title="6.7 确认(commit)"></a>6.7 确认(commit)</h4><p>当 (m,v,n,i) 条件为真的时候，副本 i 将<code>&lt;COMMIT,v,n,D(m),i&gt;</code> 向其他副本节点广播，于是就进入了确认阶段。</p><p>每个副本接受确认消息的条件是：</p><ol><li>签名正确；</li><li>消息的视图编号与节点的当前视图编号一致；</li><li>消息的序号 n 满足水线条件，在 h 和 H 之间。一旦确认消息的接受条件满足了，则该副本节点将确认消息写入消息日志中。（补充：需要将针对某个请求的所有接受的消息写入日志，这个日志可以是在内存中的）。</li></ol><p>确认阶段保证了以下这个不变式（invariant）：对某个正常节点 i 来说，如果 committed-local(m,v,n,i) 为真则 committed(m,v,n) 也为真。这个不变式和视图变更协议保证了所有正常节点对本地确认的请求的序号达成一致，即使这些请求在每个节点的确认处于不同的视图。更进一步地讲，这个不变式保证了任何正常节点的本地确认最终会确认 f+1 个更多的正常副本。</p><p>每个副本节点 i 在 committed-local(m,v,n,i) 为真之后执行 m 的请求，并且i的状态反映了所有编号小于 n 的请求依次顺序执行。这就确保了所有正常节点以同样的顺序执行所有请求，这样就保证了算法的正确性（safety）。在完成请求的操作之后，每个副本节点都向客户端发送回复。副本节点会把时间戳比已回复时间戳更小的请求丢弃，以保证请求只会被执行一次。</p><h4 id="6-8-检查点-垃圾回收"><a href="#6-8-检查点-垃圾回收" class="headerlink" title="6.8 检查点/垃圾回收"></a>6.8 检查点/垃圾回收</h4><p>为了节省内存，系统需要一种将日志中的无异议消息记录删除的机制。为了保证系统的安全性，节点在删除自己的消息日志前，需要确保至少 f+1 个正常节点执行了消息对应的请求，并且可以在视图变更时向其他节点证明。另外，如果一些节点错过部分消息，但是这些消息已经被所有正常节点删除了，这就需要通过传输部分或者全部服务状态实现该节点的同步。因此，节点同样需要证明状态的正确性。</p><p>在每一个操作执行后都生成这样的证明是非常消耗资源的。因此，证明过程只有在请求序号可以被某个常数（比如100）整除的时候才会周期性地进行。我们将这些请求执行后得到的状态称作检查点（checkpoint），并且将具有证明的检查点称作稳定检查点（stable checkpoint）。</p><p>节点保存了服务状态的多个逻辑拷贝，包括最新的稳定检查点，零个或者多个非稳定的检查点，以及一个当前状态。写时复制技术可以被用来减少存储额外状态拷贝的空间开销。</p><p>检查点的正确性证明的生成过程如下：当节点i生成一个检查点后，向其他节点广播检查点消息<code>&lt;CHECKPOINT,n,d,i&gt;</code>，这里 n 是最近一个影响状态的请求序号，d是状态的摘要。每个节点都默默地在各自的日志中收集并记录其他节点发过来的检查点消息，直到收到来自 2f+1 个不同节点的具有相同序号n和摘要d的检查点消息。这2f+1 个消息就是这个检查点的正确性证明。</p><p>具有证明的检查点成为稳定检查点，然后从节点就可以将所有序号小于等于n的预准备、准备和确认消息从日志中删除。同时也可以将之前的检查点和检查点消息一并删除。</p><p>检查点协议可以用来更新水线（watermark）的高低值（h和H），这两个高低值限定了可以被接受的消息。水线的低值h与最近稳定检查点的序列号相同，而水线的高值H=h+k，k 需要足够大才能使节点不至于为了等待稳定检查点而停顿。加入检查点每100个请求产生一次，k的取值可以是200。</p><h4 id="6-9-视图更换-view-change"><a href="#6-9-视图更换-view-change" class="headerlink" title="6.9 视图更换(view change)"></a>6.9 视图更换(view change)</h4><p>当主节点挂了（超时无响应）或者从节点集体认为主节点是问题节点时，就会触发 view change 事件，view change完成后，视图编号将会加1。</p><p>下图展示 view change 的三个阶段流程：</p><img src="/images/2019/pbft_2.png"><p>如图所示，view change 会有三个阶段，分别是 view-change，view-change-ack 和 new-view 阶段。从节点认为主节点有问题时，会向其它节点发送 view-change 消息，当前存活的节点编号最小的节点将成为新的主节点。当新的主节点收到2f个其它节点的 view-change 消息，则证明有足够多人的节点认为主节点有问题，于是就会向其它节点广播 new-view 消息。注意：从节点不会发起 new-view 事件。对于主节点，发送new-view 消息后会继续执行上个视图未处理完的请求，从 pre-prepare 阶段开始。其它节点验证 new-view 消息通过后，就会处理主节点发来的 pre-prepare 消息，这时执行的过程就是前面描述的 PBFT 过程。到这时，正式进入 v+1（视图编号加1）的视图了。</p><h4 id="6-10-算法复杂度"><a href="#6-10-算法复杂度" class="headerlink" title="6.10 算法复杂度"></a>6.10 算法复杂度</h4><p>PBFT 算法核心流程有三个阶段，分别是 pre-prepare（预准备）阶段，prepare（准备）阶段和 commit（提交）阶段。对于 pre-prepare 阶段，主节点广播 pre-prepare 消息给其它节点即可，因此通信次数为 n-1；对于 prepare 阶段，每个节点如果同意请求后，都需要向其它节点再 广播 parepare消息，所以总的通信次数为$n<em>(n-1)$，即$n^2-n$；对于 commit 阶段，每个节点如果达到 prepared 状态后，都需要向其它节点广播 commit 消息，所以总的通信次数也为$n</em>(n-1)$，即$n^2-n$。所以总通信次数为$(n-1)+(n^2-n)+(n^2-n)$，即$2n^2-n-1$，因此 pbft 算法复杂度为$O(n^2)$。</p><h3 id="7-HotStuff"><a href="#7-HotStuff" class="headerlink" title="7. HotStuff"></a>7. HotStuff</h3><p>一句话描述 HotStuff ： <strong>HotStuff 是一个在部分同步网络模型下的基于主节点的拜占庭容错共识协议。</strong> </p><blockquote><p>We present HotStuff, a leader-based Byzantine fault-tolerant replication protocol for the partially synchronous model.</p></blockquote><h4 id="7-1-PBFT-缺点"><a href="#7-1-PBFT-缺点" class="headerlink" title="7.1 PBFT 缺点"></a>7.1 PBFT 缺点</h4><p>原始的 PBFT 算法在设计时考虑的是部署在本地的只有 n = 4 或者 n = 7 个节点的网络，所以 PBFT 算法在现有的网络环境下有很大的缺陷。PBFT 中每个节点都需要与其他的节点进行 P2P 的共识同步，因此随着节点数量的增多，整体系统的性能会发生线性的速度下降。PBFT 由于其封闭性（节点数目提前确定并互相联通）和高性能开销($O(n^2)$的消息复杂度)，复杂的 view change 算法和开销，当节点数目 n = 2000 时，每次共识消息量将会爆炸到 4,000,000 ，已经不太适合现有的需求。</p><img src="/images/2019/hotstuff_0.png"><h4 id="7-2-HotStuff-流程"><a href="#7-2-HotStuff-流程" class="headerlink" title="7.2 HotStuff 流程"></a>7.2 HotStuff 流程</h4><p>HotStuff <strong>将视图切换流程和正常流程进行合并</strong>，即不再有单独的视图切换流程，降低了视图切换的复杂度。在 HotStuff 中切换视图时，系统中的某个节点也无需再确认“足够多的节点希望进行视图切换”这一消息后再通知新的主节点，它直接切换到新视图并通知新的主节点。HotStuff 把确认“足够多的节点希望进行视图切换”这一消息的行为放进了正常流程中。这一做法比较新颖，但必然会给正常流程引入新的确认阶段。因此，HotStuff 把 PBFT 的两阶段确认扩展成了三阶段确认。</p><p>HotStuff 以 prepare 阶段作为协议的开始阶段。在这一阶段中，当主节点收集到足够的节点发来新视图请求后，它开始新视图并提出自己的状态迁移要求，发送 prepare 消息给其它节点。系统中的其它节点在接收到 prepare 消息后，验证其合法性并进行如下三阶段确认：</p><ol><li><strong>pre-commit</strong> 阶段：其它节点对 prepare 消息进行投票。在收到足够多的投票后，主节点向所有节点广播 pre-commit 消息，向它节点表明足够多的节点确认了此次状态迁移的要求。 </li><li><strong>commit</strong> 阶段：其它节点对 pre-commit 消息进行投票。在收到足够多的投票后，主节点向所有节点广播 commit 消息。此时，收到 commit 消息的节点可以锁定当前状态迁移要求以便即使视图切换也可以顺利达成共识。</li><li><strong>decide</strong> 阶段：其它节点对 commit 消息进行投票。在收到足够多的投票后，主节点向所有节点广播 decide 消息。当某个节点收到 decide 消息后将执行状态迁移，并开始新的视图。</li></ol><img src="/images/2019/hotstuff_2.png"><h4 id="7-3-HotStuff-主要优化"><a href="#7-3-HotStuff-主要优化" class="headerlink" title="7.3 HotStuff 主要优化"></a>7.3 HotStuff 主要优化</h4><h5 id="7-3-1-通信复杂度优化"><a href="#7-3-1-通信复杂度优化" class="headerlink" title="7.3.1 通信复杂度优化"></a>7.3.1 通信复杂度优化</h5><p>HotStuff 每次通信都依靠主节点。节点不再通过 p2p 网络将消息广播给其它节点，而是将消息发送给主节点，由主节点处理后发送给其它节点, 系统的通信复杂度得到了大大降低。</p><p>传统 BFT 达成共识的方法是两轮共识，其中第一轮 prepare ，第二轮 commit。很多将 BFT 用于区块链的项目仍旧采取<strong>先做两轮通信，然后达成共识，最后上链</strong>的模式，而 Hotstuff 采用的是<strong>先上链，在区块中加入门限签名(threshold signature)</strong>，于是在 n 个区块之后就可以视为通过了 n 轮的通信达成共识。所以根本就不需要再去区分所谓 prepare，commit 这两轮通信的区别了，只需要简单地把每一轮节点的行为定义成<strong>leader负责出块和收集签名</strong>，然后<strong>其他节点负责对leader出的块进行签名</strong>，然后，只要收集到了2f+1 个签名，leader 就可以出一个块，然后后面有 n 个块就相当于达成了共识。这点的好处在于，O(n) 的通信复杂度可以让诚实节点知道 <strong>我知道消息 m 将成为共识</strong>，但是必须要 $O(n^2)$ 的通信才能让每个诚实节点都确信 <strong>我还知道所有诚实节点也知道消息m是共识</strong> ，而通过 leader 收集签名并出块这种方法，当所有人看到区块 b 的时候，诚实节点会知道 <strong>我知道b是共识</strong>，而在看到 b 后一块 b’ 的时候，诚实节点等于知道了<strong>所有签名的人也都知道了 b 是共识</strong>。于是，每次出块的时候都只需要 O(n) 的消息复杂度，但是，在一个诚实 leader 和聚合签名的帮助下，通过两轮的O(n)消息复杂度，我们达到了之前 $O(n^2)$ 的效果。</p><h5 id="7-3-2-引入门限签名（threshold-signature）"><a href="#7-3-2-引入门限签名（threshold-signature）" class="headerlink" title="7.3.2 引入门限签名（threshold signature）"></a>7.3.2 引入门限签名（threshold signature）</h5><p>为了提升效率，一个直觉的思路是：<strong>避免 $O(n^2)$ 的通讯</strong>。我们可以指定网络中的某节点作为协调者来发送/接收每个节点的投票，这样每个节点都只需要向协调者发送讯息即可，从而避免了 $O(n^2)$ 的通讯。然而，在这样的情境下，协调者有作恶的可能，因为协调者可以在未确实接收到指定数量的讯息前便执行下一轮投票或者进行状态更新。</p><p>我们可以使用门限签名来保证协调者的正当行为，门限签名可以保证：需集合<strong>超过门限数量(t-of-n)的签名才有效</strong>。也就是说，我们可以指定：唯有当协调者集合 2f+1 个签名后，协调者才能带着合法的签名继续推进共识，这在之前已经有很多项目采用这种做法，比如：Dfinity。</p><img src="/images/2019/hotstuff_4.jpg"><h5 id="7-3-3-流水线作业"><a href="#7-3-3-流水线作业" class="headerlink" title="7.3.3 流水线作业"></a>7.3.3 流水线作业</h5><p>其它节点对某一消息进行投票，主节点合成投票意见并通知给其它节点。这些过程可以统一表示，并采用流水化来处理。</p><img src="/images/2019/hotstuff_3.png"><p>如果每个内容都必须经过二轮投票/三个阶段才能达成共识，如果有 m 个内容就需要执行 2m 次投票。管线设计(Pipelining)可以减少投票的次数，HotStuff 的基本思路如下：让每个节点在投第 i 轮的 prepare 阶段时，同时也是对其前一个内容 i-1 的 commit 阶段投票。这样做便可以节省对同一个内容重复投票的冗余，大幅提升效率。</p><h5 id="7-3-4-view-change-优化"><a href="#7-3-4-view-change-优化" class="headerlink" title="7.3.4 view change 优化"></a>7.3.4 view change 优化</h5><p>PBFT 中当发生 view change 时，需要节点对 view change 达成共识，然后节点把这个共识（以及已经达成了共识这件事）告诉新的 leader，新的 leader 还要把这个消息广播出去宣布 view change，于是 view change的复杂度是 $O(n^3)$ , 采用了聚合签名之后是 $O(n^2)$。这带来两个问题：</p><ul><li>view change 的消息复杂度，</li><li>view change 必须要等到节点对于 view change 达成共识之后才会发生。</li></ul><p>Hotstuff  把 PBFT 的两轮共识变成了三轮，然后借此把 view change 的复杂度变成了 O(n)。这个可以这么理解：传统的 view change是 $O(n^2)$ 消息复杂度，也就是说，所有的节点在 view change 之前会确认所有的节点确实都进行到下一个 view，而在 Hotstuff 中，view change 不需要等<strong>我知道其他人也知道 view change 了</strong>这件事就可以进行，于是，消息复杂度就降到了 $O(n)$，也就是说，只要诚实节点的内置 time out 到了，那么就可以发 view change 给新的 leader 开始 view change。</p><p>HotStuff 为什么需要把两轮变成三轮呢？上面提到的 BFT+Chain 结构的简化中，严格来说这两个通信复杂度为 $O(n)$ 的区块和 PBFT $O(n^2)$消息复杂度的 prepare 和 commit 还是有区别的，当有两个区块连起来的时候两边是相当的，但是其实每一个区块的消息复杂度都只有 $O(n)$，并不说明所有诚实节点都知道–<strong>所有诚实节点都会达成共识</strong>。而同样，view change 的消息复杂度也只有 O(n)，于是如果一条消息刚有第一个区块的时候view change 了，那么诚实节点会对于第一个区块是否达成了共识产生不一致，因为 prepare 和 view change看起来都很有道理。</p><p>而把两轮变成三轮之后我们就解决了这个问题。因为我们可以规定任何两轮之后的东西才是共识，而如果没有到两轮就不算–<strong>对于 prepare 和 view change 都是如此</strong>。于是，如果 view change 发生在第一轮之后，那么我们不认为之前 prepare 的是正确的，而 view change 也同理。相反，如果在第二轮之后发生 view change，那么由于已经经过了两轮，所以这条消息已经经过了 prepare，即便在 view change 之后也会最终达成共识。</p><h5 id="7-3-5-Pacemaker-机制"><a href="#7-3-5-Pacemaker-机制" class="headerlink" title="7.3.5 Pacemaker 机制"></a>7.3.5 Pacemaker 机制</h5><p>HotStuff 通过 pacemaker 机制从算法层面对共识安全（safety）和活性（liveness) 进行解耦合，将保证系统安全的部分抽离出来，然后将与具体应用相关的 heuristics 部分分离，来实现 liveness。</p><blockquote><p>HotStuff also implements a mechanism called <em>Pacemaker</em>, that guarantees liveness after GST. Pacemaker a) synchronizes all correct replicas and a unique leader into a common height for a sufficiently long period of time. It chooses the unique leader such that the correct replicas synchronized will make progress with the chosen leader. This mechanism decouples <strong>liveness</strong> from the protocol, which in turn decouples it from <strong>safety</strong>.</p></blockquote><h4 id="7-4-总结"><a href="#7-4-总结" class="headerlink" title="7.4 总结"></a>7.4 总结</h4><p>总体来说，Hotstuff 的核心思路如下：</p><ol><li><p>采用门限签名把每一轮的消息复杂度变成 $O(n)$。</p></li><li><p>用 BFT+Chain 结构把 $O(n^2)$ 的共识变成了两轮 $O(n)$ 消息复杂度的区块提交。</p></li><li><p>在这种结构下，把 view change 的消息复杂度降到 $O(n)$，然后为了防止 view change 造成的不一致，把两轮区块提交变成了三轮。</p></li><li><p>共识过程采用流水化处理。</p></li></ol><h3 id="8-LibraBFT"><a href="#8-LibraBFT" class="headerlink" title="8. LibraBFT"></a>8. LibraBFT</h3><h4 id="8-1-LibraBFT-简介"><a href="#8-1-LibraBFT-简介" class="headerlink" title="8.1 LibraBFT 简介"></a>8.1 LibraBFT 简介</h4><p>LibraBFT[^5] 基于 HotStuff[^4] ，进一步完善了 HotStuff 协议，LibraBFT 在 HotStuff的基础上引入显示的活跃机制并提供了具体的延时分析。LibraBFT在一个有全局统一时间（GST），并且网络最大延时（ΔT）可控的 Partial Synchrony 的网络中是有效的。并且，LibraBFT在所有验证节点都重启的情况下，也能够保证网络的一致性。</p><blockquote><p>LibraBFT is ==based on HotStuff==, a recent protocol that leverages several decades of scientific advances in Byzantine fault tolerance (BFT) and achieves the strong scalability and security properties required by internet settings. </p></blockquote><p>LibraBFT 每一轮(round)共识都会选举出一个 leader 节点，然后由 leader 节点发起提案(proposals)，收集投票(vote)，最后达成共识。在 LibraBFT 中，所有参与共识的节点称之为 validator，即验证节点。</p><p>LibraBFT 是变体的 HotStuff chain(这个链不是 block chain ,而是用于共识的 hash 链),在 HotStuff 的每轮(round)共识流程中，所有的信息交互都只和 leader 节点进行，然后 leader 节点的提案会以一条加密的 hash链组成(HotStuff chain)。在每轮共识中，被选举出的 leader 节点会基于节点自身最长的 HotStuff chain 提出 block 提案，如果提案是有效并且及时，剩余的诚实节点会使用自身的私钥签名该提案，并将通过的 vote 发送回 leader节点。当 leader 节点收集到足够的 (Quorum vote) 时，会将 vote 聚合成 Quorum证书(Quorum Certificate，QC)，当然，leader 会基于上述已延伸的最长 HotStuff chain 继续追加 QC，换言之，一轮共识成功后，leader 节点会基于自身最长的 HotStuff chain，按序追加提案 block(缩写B) 以及 QC(缩写C)，然后在将 QC 再次广播至剩余的节点，并开启下一轮的共识。当然这是共识成功的情况。在异常情况下，无论任何原因，如果当前 leader 节点没法及时共识成功，共识参与者会一直等到当前 round 的超时时间，然后在发起下一轮的共识。</p><p> 最后，如果足够的 blocks 以及 QCs 都能连续及时的通过共识，并且其中一个 block 达到了 commit 条件，那么，该 block 会被 commit ，换言之，该 block 以及 block 中 transaction 集合都会被落盘，并被确认。</p><img src="/images/2019/librabft_0.png"><pre><code>                                                                                   HotStuff Chain</code></pre><p> 上图描述的 HotStuff Chain，其可以表现为： 【ℎinit ← 𝐵1 ← 𝐶1 ← 𝐵2 ← 𝐶2 … ← 𝐵𝑛+1 ← 𝐶𝑛+1】</p><h4 id="8-2-LibraBFT-共识流程"><a href="#8-2-LibraBFT-共识流程" class="headerlink" title="8.2 LibraBFT 共识流程"></a>8.2 LibraBFT 共识流程</h4><p>根据论文描述 LibraBFT 流程如下图：</p><img src="/images/2019/librabft_1.png"><pre><code>             Overview of the LibraBFT protocol (simplified, excluding round synchronization)                                                                        </code></pre><p>*<em>简单分析： *</em></p><ol><li>round 1 的 leader node3 出了 block B1，广播消息到所有 nodes。</li><li>其它 node 同意，回传 vote V1。</li><li>node3 收集投票 (包含自己的 vote)，形成 C1，传给所有 nodes。</li><li>(3 和 1 之间的间隔时间) node0 是 round 2 的 leader，收集其它 nodes 的状态，确定有 <code>N — f</code> 个 nodes 进入 round 2 后，产生 B2，回到步骤 1 ~ 3。</li></ol><p><strong>详细分析：</strong></p><p>通过 round 3 来详细分析共识流程：</p><ol><li><p>node1 被选举为 leader 节点，然后 node1 会基于自身最长链尾部 C2 发起 B3 提案，然后将提案广播至剩余节点(node0，2，3)，广播完成后，node1 会执行 B3 中的 transaction 列表，得到 execute state；</p></li><li><p>当剩余节点(node0，2，3)收到 B3提案后，会执行 B3 中的交易，然后将 execute state 打包到 vote 中，在将其签名，并发送给 node1;</p></li><li><p>一起都正常情况下，node1 会收到自身以外的 vote 请求，当收集到足够多的 vote 时，并且 vote 验证通过,包括 execute state 、签名、round 等，leader 节点会将 vote 集合打包成 quorum certificate(QC)，并将 QC 广播至剩余节点，到这里，一轮共识完毕。     </p></li></ol><p><strong>block 提交</strong><br>共识轮次(round)用 int 表示，并且只会递增。在每一轮共识轮次中，都仅由一个 leader 节点发起一次提案，轮次仅在共识成功后或当前共识轮次超时才会结束，然后轮次自增1，启动下轮次共识。因此，假设 round(Bi) 为提案 Bi 的当前轮次值，并且，依据递增的规定可以得到 round(𝐵𝑖) &lt; round(𝐵𝑖+1)；另外，如果 round(𝐵𝑖) + 1 = round(𝐵𝑖+1)，我们则称之为连续共识成功两轮，代表在这两轮共识中，都没有发生超时，并且共识都成功。如果同时满足以下两个条件：</p><ul><li>𝐵1 ← 𝐶1 ← 𝐵2 ← 𝐶2 ← 𝐵3 ← 𝐶3</li><li>round(𝐵3) = round(𝐵2) + 1 = round(𝐵1) + 2</li></ul><p>那么，B1 则会被 commit，换言之，连续三个共识轮次成功的情况下，第一个共识的 block 就会被提交。总的来说，相对于 PBFT 的三阶段提交来说，LibraBFT 的只需1.5阶段，既可完成一轮共识，上述的 round(B3) 完成后，round(B1) 才会被 commit 相当于 PBFT 的 commit 阶段。其实这就是 HotStuff 中的做法。</p><h4 id="8-3-Data-Synchronization"><a href="#8-3-Data-Synchronization" class="headerlink" title="8.3 Data Synchronization"></a>8.3 Data Synchronization</h4><p>Leader 在提案以前，会先确保足够人数进入同一 round 才会出块。nodes 之间会定时互相传播自己的状态，然后向別人取得缺少的部份。同步的流程为:</p><ol><li>广播 DataSyncNotaification。</li><li>依其它人的状态，向对方发送 DataSyncRequest。</li><li>收到 DataSyncRequest 后，回复 DataSyncResponse。</li></ol><p>目前的实现，request 一次传自己全部的状态，response 一次回复全部缺少的部份。详细实现如下:</p><img src="/images/2019/librabft_2.png"><p>目前代码跟白皮书上的伪代码有出入。</p><h4 id="8-4-Voting-Constraint"><a href="#8-4-Voting-Constraint" class="headerlink" title="8.4 Voting Constraint"></a>8.4 Voting Constraint</h4><p>符号说明：</p><ul><li>B 表示 区块(block)。</li><li>C 表示 (法定证书)quorum certificate。</li><li>B ← C 表示 C 的上一个 record 指向 B，即 C 有记录 B 的 hash。</li><li>round(B) 表示 B 的 round 是多少。</li><li>对 B’ ← C’ ← B 来说，previous_round(B) 表示 round(B’)</li></ul><p>除了只能投目前 round 的 block 以外，nodes 投票时还要遵守两个规则:</p><ul><li>First voting constraint: 投过 round x 的票后只能投 round y (y &gt; x) 的票。</li><li>Second voting constraint: 看过 2-chain B0 ← C0 ← B1 ← C1 后，收到新的 block B，previous_round(B) ≥ round(B0)</li></ul><p>第一个规则符合自觉，只能投更新的 block。若同一 round 里，leader 不守规则产生两个不同的 block，voter 只会投看到的第一个，不会 double vote。</p><p>第二个规则表示有看到两个连续通过的 block 后，新的 block B 至少要指向 B0 或 round 数比它大的 block。注意，这里沒有要求 B 所在的 chain 上面一定有 B0。</p><h4 id="8-5-Commit-Rule"><a href="#8-5-Commit-Rule" class="headerlink" title="8.5 Commit Rule"></a>8.5 Commit Rule</h4><p>对 3-chain B0 ← C0 ← B1 ← C1 ← B2 ← C2 且 round(B2) = round(B1)+1 = round(B0)+2 来说，B0 以及它之前的 records 的状态称为 committed，一但 committed，表示记录就不会掉了。</p><p>QC 有个选择性的栏位 commitment，用来记录最新的 committed state。以这里的例子来说，C2 的 commitment 会记录 state(C0)。</p><p>只管来说，若 node A 看到上述的 B0 ← … ← C2，表示 A 知道有 <code>N — f</code> 的 nodes 知道 B0 ← C0 ← B1 ← C1。所以之后通过的 block B，会满足 previous_round(B) ≥ round(B0)。表示 B 所在的 chain 上必定包含 B0。</p><h4 id="8-6-Punishment"><a href="#8-6-Punishment" class="headerlink" title="8.6 Punishment"></a>8.6 Punishment</h4><p>有了 voting constraint 和 commit rule，大家可以举报谁不遵守规则，验证后可惩罚 (例如沒收 stake-in 的 token)。</p><h4 id="8-7-Network"><a href="#8-7-Network" class="headerlink" title="8.7 Network"></a>8.7 Network</h4><p>文中提到在 P2P synchronization protocol 之上有加一层 gossip overlay，在 broadcast 的时候会随机传給 K (≤N) 个 nodes，然后通过收到的 nodes 继续传播消息。不过为简化讨论，假设 K = N。</p><p>考虑到网络状态会变化，timeout 的值由以下公式确定:</p><pre class=" language-rust"><code class="language-rust"><span class="token function">duration</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token operator">=</span> delta <span class="token operator">*</span> <span class="token punctuation">(</span>n <span class="token operator">-</span> nc <span class="token operator">-</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">^</span>r</code></pre><ul><li>n 表示目前的 round。</li><li>nc 表示最后一个 committed block 的 round。</li><li>delta 和 r 是常数。</li></ul><p>直观来说，愈久没有新的 committed block，timeout 时间愈久。假设无法同意新的 block 是因为网络状态不佳，逐渐加长 timeout 时间合理。但若是因为 byzantine node (拜占庭节点) 造成的，反而让 byzantine node 拖更久没有 liveness。实际情况依「拜占庭节点和网络状态不佳」何者更容易发生，来决定参数怎么设置。</p><h4 id="8-8-总结"><a href="#8-8-总结" class="headerlink" title="8.8 总结"></a>8.8 总结</h4><p>We have presented LibraBFT, a state machine replication system based on the HotStuff protocol [5]<br>and designed for the Libra Blockchain [2]. LibraBFT provides safety and liveness in a Byzantine<br>setting when up to one-third of voting rights are held by malicious actors, assuming that the network is partially synchronous. In this report, we have presented detailed proofs of safety and liveness and covered many important practical considerations, such as networking and data structures. We have shown that LibraBFT is compatible with proof of stake and can generate incentives for a variety of behaviors, such as proposing blocks and voting. Thanks to the simplicity of the safety argument in LibraBFT, we also provided criteria to detect malicious attempts to break safety. These criteria will be instrumental for the progressive migration of the Libra infrastructure to a permissionless model.</p><h4 id="8-9-Future-work"><a href="#8-9-Future-work" class="headerlink" title="8.9 Future work"></a>8.9 Future work</h4><p>This report constitutes an initial proposal for LibraBFT and is meant to be updated in the future. In the next version, we intend to share the code for our reference implementation in a simulated environment and provide experimental results, both using this simulation and using the production implementation currently developed by Calibra engineers.</p><p>In the future, we would like to improve our theoretical analysis in several ways. We plan to make<br>our networking assumptions more precise, with additional studies on message sizes and probabilistic gossiping. Regarding the integration of LibraBFT with the Libra Blockchain, we would like to cover fairness and discuss how light clients can authenticate the set of validators for each epoch. Economic incentives should reward additional positive behaviors, such as creating timeouts, and specifications should provide an external protocol for auditors to report violations of safety rules.</p><p>On a practical level, we have not yet analyzed resource consumption (memory, CPU, etc.) in the<br>presence of malicious participants. Heuristics for leader selection, a precise description of the VRF<br>solution, and possibly adaptive policies will likely be required to increase the robustness of the system in case of malicious leaders or targeted attacks on leaders.</p><p>In the long term, we hope that our efforts on precise specifications and detailed proofs will pave the<br>way for mechanized proofs of safety and liveness of LibraBFT.</p><h3 id="9-参考资料"><a href="#9-参考资料" class="headerlink" title="9. 参考资料"></a>9. 参考资料</h3><ul><li><a href="https://arxiv.org/pdf/1803.05069.pdf" target="_blank" rel="noopener">HotStuff: BFT Consensus in the Lens of Blockchain</a></li><li><a href="https://developers.libra.org/docs/papers/libra-consensus-state-machine-replication-in-the-libra-blockchain.pdf" target="_blank" rel="noopener">State Machine Replication in the Libra Blockchain</a></li><li><a href="https://zhuanlan.zhihu.com/p/72776441" target="_blank" rel="noopener">Libra 采用的 HotStuff 算法作者亲述：「尤物」诞生记</a></li><li><a href="https://www.chainnews.com/articles/215569914405.htm" target="_blank" rel="noopener">一文简述 HotStuff 的工作原理</a></li><li><a href="https://bbs.vechainworld.io/topic/200/librabft算法简述" target="_blank" rel="noopener">LibraBFT算法简述</a></li></ul><p>[^4]: M. Yin, D. Malkhi, M. K. Reiterand, G. G. Gueta, and I. Abraham, “HotStuff: BFT consensus</p><p>in the lens of blockchain,” 2019. <a href="https://arxiv.org/pdf/1803.05069.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1803.05069.pdf</a></p><p>[^5]: State Machine Replication in the Libra Blockchain <a href="https://developers.libra.org/docs/papers/libra-consensus-state-machine-replication-in-the-libra-blockchain.pdf" target="_blank" rel="noopener">https://developers.libra.org/docs/papers/libra-consensus-state-machine-replication-in-the-libra-blockchain.pdf</a><br>[^6]: Impossibility of Distributed Consensus with One Faulty Process  <a href="https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf" target="_blank" rel="noopener">https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf</a><br>[^7]: <a href="https://en.wikipedia.org/wiki/Clock_drift" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Clock_drift</a><br>[^8]: <a href="https://en.wikipedia.org/wiki/Clock_skew" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Clock_skew</a><br>[^9]: <a href="https://en.wikipedia.org/wiki/Network_Time_Protocol" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Network_Time_Protocol</a><br>[^10]: <a href="https://en.wikipedia.org/wiki/Real-time_clock" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Real-time_clock</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Blockchain </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Blockchain </tag>
            
            <tag> Libra </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IO</title>
      <link href="/2020/05/20/io/"/>
      <url>/2020/05/20/io/</url>
      
        <content type="html"><![CDATA[<p>文件 I/O 的性能对数据库系统的性能有直接的影响，我们需要全面了解和掌握文件I/O。</p><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>Linux 文件系统采用分层设计，对不同层进行抽象达到架构清晰、解耦的作用。</p><h3 id="Linux-Storage-Stack"><a href="#Linux-Storage-Stack" class="headerlink" title="Linux Storage Stack"></a>Linux Storage Stack</h3><img src="/images/2015/Linux-storage-stack-diagram_v4.10.png"><h2 id="硬盘"><a href="#硬盘" class="headerlink" title="硬盘"></a>硬盘</h2><img src="/images/2015/disk_26.png"><p>HDD 和早期 SSD 绝大多数都是使用 SATA 接口，跑的是 AHCI（Advanced Host Controller Interface），它是由Intel联合多家公司研发的系统接口标准。AHCI 支持 NCQ（Native Command Queuing）功能和热插拔技术。NCQ 最大深度为32，即主机可以发最多32条命令给 HDD 或者 SSD 执行，跟之前硬盘只能一条命令一条命令执行相比，硬盘性能大幅提升。</p><p>这在 HDD 时代，或者 SSD 早期，AHCI 协议和 SATA 接口足够满足系统性能需求，因为整个系统性能瓶颈在硬盘端（低速，高延时），而不是在协议和接口端。然而，随着 SSD 技术的飞速发展，SSD 盘的性能飙升，底层闪存带宽越来越宽，介质访问延时越来越低，系统性能瓶颈已经由下转移到上面的接口和协议处了。AHCI 和 SATA已经不能满足高性能和低延时 SSD 的需求，因此 SSD 迫切需要自己更快、更高效的协议和接口。</p><p>在这样的背景下，NVMe 横空出世。2009年下半年，在带头大哥 Intel 领导下，美光、戴尔、三星、Marvell等巨头，一起制定了专门为 SSD 服务的 NVMe 协议，旨在让 SSD 从老旧的 SATA 和 AHCI 中解放出来。</p><p>何为NVMe？Non-Volatile Memory Express，非易失性存储器标准，是跑在 PCIe 接口上的协议标准。NVMe 的设计之初就有充分利用到 PCIe SSD 的低延时以及并行性，还有当代处理器、平台与应用的并行性。SSD的并行性可以充分被主机的硬件与软件充分利用，相比于现在的 AHCI 标准，NVMe 标准可以带来多方面的性能提升。NVMe为SSD而生，但不局限于以闪存为媒介的SSD，它同样可以应用在高性能和低延时的3D XPoint这类新型的介质上。</p><p>NVMe和AHCI相比，它的优势主要体现在以下几点：</p><p><strong>低时延（Latency）</strong></p><p>造成硬盘存储时延的三大因素：存储介质本身、控制器以及软件接口标准。</p><p>存储介质层面，闪存（Flash）比传统机械硬盘速度快的太多；</p><p>控制器方面，从 SATA SSD 发展成 PCIe SSD，原生 PCIe 主控与 CPU 直接相连，而不是传统方式，通过南桥控制器中转，再连接 CPU，因此基于 PCIe 的 SSD 时延更低；</p><p>软件接口方面，NVMe 缩短了 CPU 到 SSD 的指令路径，比如 NVMe 减少了对寄存器的访问次数；MSI-X 和中断管理的应用；并行&amp;多线程优化，NVMe 减少了各个 CPU 核之间的锁同步操作。</p><p>所以基于 PCIe+NVMe 的SSD，具有非常低的延时。</p><img src="/images/2015/nvme1.png"><p><strong>高性能（Throughput &amp; IOPS）</strong></p><p>理论上，IOPS=队列深度/ IO延迟，故 IOPS 的性能，与队列深度有较大的关系（但 IOPS 并不与队列深度成正比，因为实际应用中，随着队列深度的增大，IO 延迟也会提高）。市面上性能不错的 SATA 接口 SSD，在队列深度上都可以达到32，然而这也是 AHCI 所能做到的极限。但目前高端的企业级 PCIe SSD，其队列深度可能要达到128，甚至是256才能够发挥出最高的 IOPS 性能。而 NVMe 标准下，最大的队列深度可达64K。此外，NVMe 的队列数量也从 AHCI 的1，提高到了64K。</p><p>PCIe 接口本身在性能上碾压 SATA，再加上 NVMe具有比AHCI 更深、更宽的命令队列，NVMe SSD 在性能上秒杀 SATA SSD 是水到渠成的事情。图是 NVMe SSD，SAS SSD和SATA SSD 性能对比图：</p><img src="/images/2015/nvme2.png"><p><strong>低功耗</strong></p><p>NVMe加入了自动功耗状态切换和动态能耗管理功能</p><h3 id="硬盘分类"><a href="#硬盘分类" class="headerlink" title="硬盘分类"></a>硬盘分类</h3><p>硬盘的种类比较多，若是按照硬盘接口类型的不同来分，大致可以分为 IDE 硬盘、SATA 硬盘、SCSI 硬盘、移动硬盘、固态硬盘。<br> 硬盘按照其工作形式的不同可以分为两种，一种是机械硬盘，另一种是固态硬盘。比较常见的机械硬盘按照其接口形式的不同可以分为 IDE 硬盘、SATA 硬盘、SCSI 硬盘三种。</p><p><strong>IDE 硬盘</strong></p><img src="/images/2015/disk_10.png"><p>IDE（Integrated Drive Electronics）硬盘是指采用 IDE 接口的硬盘。如图，为 IDE 硬盘。IDE 是所有现存并行 ATA 接口规格的统称。这种硬盘相对来说价格低廉、兼容性强、工作稳定、容量大、噪音低，应用比较多。但是，这种硬盘采用并行数据传输方式，传输速度的不断提升使得信号干扰逐渐变强，不利于数据的传输。</p><p><strong>SATA 硬盘</strong></p><img src="/images/2015/disk_11.png"><p>SATA（Serial Advande Technology Attachment）硬盘是指采用 SATA 接口的硬盘，如图，为 SATA 硬盘。SATA 接口采用串行数据传输方式，理论上传输速度比 IDE 接口要快很多，解决了IDE硬盘数据传输信号干扰限制传输速率的问题，并且采用该接口的硬盘支持热插拔，执行率也很高。</p><p><strong>SCSI 硬盘</strong></p><img src="/images/2015/disk_12.png"><p>SCSI（Small Computer System Interface）硬盘就是采用SCSI接口的硬盘，采用这种接口的硬盘主要用于服务器，如图为SCIS硬盘。这种接口共有50针，外观和普通硬盘接口有些相似。SCSI硬盘和普通IDE硬盘相比有很多优点：接口速度快，并且由于主要用于服务器，因此硬盘本身的性能也比较高，硬盘转速快，缓存容量大，CPU占用率低，扩展性远优于IDE硬盘，并且同样支持热插拔。</p><p><strong>固态硬盘</strong></p><p>固态硬盘（Solid State Disk）用固态电子存储芯片列阵而制成的硬盘，如图，所示为固态硬盘，它主要由控制单元和存储单元（FLASH芯片）组成。固态硬盘的接口规范和定义、功能及使用方法上与普通硬盘的完全相同，在产品外形和尺寸上与普通硬盘几乎一致。固态硬盘的存储介质分为两种，一种是采用闪存（FLASH芯片）作为存储介质，另外一种是采用DRAM作为存储介质。</p><h3 id="SSD-与-HDD-比较"><a href="#SSD-与-HDD-比较" class="headerlink" title="SSD 与 HDD 比较"></a>SSD 与 HDD 比较</h3><table><thead><tr><th></th><th align="center">SSD</th><th align="center">HDD</th></tr></thead><tbody><tr><td>启动时间</td><td align="center">由于没有马达和转臂，所以几乎可以瞬间完成。<br>同时从休眠模式中唤醒也大约只需要几毫秒即可。</td><td align="center">可能需要数秒以启动马达。而且当磁盘量非常大的时候，需要依次启动以防止瞬间电流过载。</td></tr><tr><td>随机访问时间</td><td align="center">大约仅需0.1毫秒，因为无需寻道。</td><td align="center">大约需要5–10毫秒。</td></tr><tr><td>读取潜伏期</td><td align="center">通常很短，因为直接读取。</td><td align="center">通常比较高，因为磁头需要额外的时间等待扇区的到来。</td></tr><tr><td>读取性能一致性</td><td align="center">读取性能不因数据在SSD上的存储位置不同而不同。</td><td align="center">读取性能与存放在磁盘的内圈还是外圈有关，也与文件的碎片程度有关。</td></tr><tr><td>碎片整理</td><td align="center">SSD基本不需要进行碎片整理，因为读取连续的数据并不明显比读取分散的数据快。<br>并且碎片整理会额外增加NAND闪存的写入次数，从而降低其寿命。</td><td align="center">HDD通常需要在文件碎片达到一定程度后进行整理，否则性能会有明显下降。特别是在含有大量文件的情况下更是如此。</td></tr><tr><td>噪音</td><td align="center">SSD无任何噪音</td><td align="center">HDD有明显的噪音，并且在读写频繁的时候噪音更大。</td></tr><tr><td>机械可靠性</td><td align="center">无机械故障</td><td align="center">随着时间的推移，机械故障概率会逐渐增加。</td></tr><tr><td>环境敏感性</td><td align="center">对震动、磁场、碰撞不敏感</td><td align="center">对震动、磁场、碰撞敏感</td></tr><tr><td>体积和重量</td><td align="center">体积小、重量轻</td><td align="center">性能越高，体积和重量越大</td></tr><tr><td>并行操作</td><td align="center">多数控制器可以使用多个芯片进行并发读写</td><td align="center">HDD虽然有多个磁头，但是由于共享同一个位置控制电机，所以不能并发读写。</td></tr><tr><td>写入寿命</td><td align="center">基于闪存的SSD有写入寿命限制，且一旦损坏，整个SSD的数据都将丢失。</td><td align="center">无写入寿命限制</td></tr><tr><td>数据安全问题</td><td align="center">NAND闪存的存储块不能被直接覆盖重写，只能重新写入先前被擦除的块中。<br>如果一个软件加密程序对已经存在于SSD上的数据进行加密，那些原始的、看上去已经被覆盖掉的原始数据实际上并没有被覆盖，它们依然可以被读取，从而造成信息泄漏。<br>但是SSD自身基于硬件的加密装置没有这个问题。<br>此外，也不能简单的通过覆盖原文件的办法来清除原有的数据，除非该SSD有内建的安全删除机制，并且确实已经被启用。</td><td align="center">HDD可以直接覆盖掉指定的扇区，因而不存在这个问题。</td></tr><tr><td>单位容量成本</td><td align="center">贵。但是大约每两年下降一半。</td><td align="center">便宜</td></tr><tr><td>最大存储容量</td><td align="center">小。但是大约每两年可翻一倍。</td><td align="center">大</td></tr><tr><td>读/写性能对称</td><td align="center">低端SSD的读取速度远高于写入速度，但是高端产品的读写速度可以做到一致。</td><td align="center">HDD的读取速度通常比写入速度快一些，但是差距并不很大。</td></tr><tr><td>TRIM与可用空白块</td><td align="center">SSD的写入性能受可用空白块数量影响很大。<br>先前曾经写入过数据且现在未被使用的块，可以通过TRIM来回收，使其成为可用的空白块。<br>但是即使经过TRIM回收的块，其性能依然会出现下降。</td><td align="center">HDD完全没有这些问题，其性能不会因为多次读写而出现下降，也不需要进行TRIM操作。</td></tr><tr><td>能耗</td><td align="center">即使是高性能的SSD通常其能耗也只有HDD的1/2到1/3。</td><td align="center">高性能HDD通常需要大约12-18瓦，而为笔记本设计的节能HDD的功耗通常在2-3瓦。</td></tr></tbody></table><h3 id="HDD（Hard-Disk-Drive）"><a href="#HDD（Hard-Disk-Drive）" class="headerlink" title="HDD（Hard Disk Drive）"></a>HDD（Hard Disk Drive）</h3><p>硬盘驱动器是一种较旧的技术，最初由IBM在60多年前推出。它是硬盘驱动器的简称形式，并使用磁力进行数据存储。HDD具有高速旋转的旋转磁盘，同时其上方具有读/写头，其在旋转磁盘上读取和写入数据。HDD 的性能取决于磁盘的旋转速度。目前使用的 HDD 驱动器的通常转速范围在5,400 RPM（RPM）到7,200 RPM（RPM）之间。基于服务器的磁盘可以实现高达15,000 rpm（RPM）的旋转速度。</p><p>我们分别从硬盘的物理结构和逻辑结构分析。</p><h4 id="物理结构"><a href="#物理结构" class="headerlink" title="物理结构"></a>物理结构</h4><p>硬盘的物理结构可分为外部结构和内部结构。</p><h5 id="外部结构"><a href="#外部结构" class="headerlink" title="外部结构"></a>外部结构</h5><p>硬盘的外部结构主要包括金属固定面板、控制电路板和接口三部分。</p><p><strong>金属固定面板</strong><br>硬盘外部会有一个金属的面板，用于保护整个硬盘。<br>金属面板和地板结合成一个密封的整体，保证硬盘盘体和机构的稳定运行。</p><img src="/images/2015/disk_1.png"><p><strong>控制电路板</strong></p><p>控制电路板上的电子元器件大多采用贴片式元件焊接，这些电子元器件组成了功能不同的电子电路，这些电路包括主轴调速电路、磁头驱动与伺服定位电路、读写电路、控制与接口电路等。在电路板上有几个主要的芯片：主控芯片、BIOS芯片、缓存芯片、电机驱动芯片。</p><img src="/images/2015/disk_2.png"><p><strong>接口</strong></p><p>在硬盘的顶端会有几个不同的硬盘接口，这些接口主要包括电源插座接口、数据接口和主、从跳线接口，其中电源插口与主机电源相联，为硬盘工作提供电力保证。中间的主、从盘跳线接口，用以设置主、从硬盘，即设置硬盘驱动器的访问顺序。</p><img src="/images/2015/disk_3.png"><h5 id="内部结构"><a href="#内部结构" class="headerlink" title="内部结构"></a>内部结构</h5><p>硬盘内部主要包括磁头组件、磁头驱动组件、盘体、主轴组件、前置控制电路等。</p><img src="/images/2015/disk_4.png"><p><strong>磁头组件</strong><br>磁头组件包括读写磁头、传动手臂、传动轴三部分组成。</p><img src="/images/2015/disk_5.png"><p>磁头组件中最主要的部分是磁头，另外的两个部分可以看作是磁头的辅助装置。传动轴带动传动臂，使磁头到达指定的位置。<br>磁头是硬盘中对盘片进行读写工作的工具，是硬盘中最精密的部位之一。磁头是用线圈缠绕在磁芯上制成的，工作原理则是利用特殊材料的电阻值会随着磁场变化的原理来读写盘片上的数据。硬盘在工作时，磁头通过感应旋转的盘片上磁场的变化来读取数据；通过改变盘片上的磁场来写入数据。为避免磁头和盘片的磨损，在工作状态时，磁头悬浮在高速转动的盘片上方，间隙只有0.1~0.3um，而不是盘片直接接触，在电源关闭之后，磁头会自动回到在盘片上着陆区，此处盘片并不存储数据，是盘片的起始位置。</p><p><strong>磁头驱动组件</strong></p><p>磁头的移动是靠磁头驱动组件实现的，硬盘寻道时间的长短与磁头驱动组件关系非常密切。磁头的驱动机构由电磁线圈电机、磁头驱动小车、防震动装置构成，高精度的轻型磁头驱动机构能够对磁头进行正确的驱动和定位，并能在很短时间内精确定位系统指令指定的磁道，保证数据读写的可靠性。电磁线圈电机包含着一块永久磁铁，该磁铁的磁力很强，对于传动手臂的运动起着关键性的作用。防震装置是为了避免磁头将盘片刮伤等情况的发生而设计的。</p><p><strong>盘片与主轴组件</strong></p><p>盘片是硬盘存储数据的载体，盘片是在铝合金或玻璃基底上涂覆很薄的磁性材料、保护材料和润滑材料等多种不同作用的材料层加工而成，其中磁性材料的物理性能和磁层机构直接影响着数据的存储密度和所存储数据的稳定性。金属盘片具有很高的存储密度、高剩磁及高娇顽力；玻璃盘片比普通金属盘片在运行时具有更好的稳定性。<br>主轴组件包括主轴部件轴瓦和驱动电机等。随着硬盘容量的扩大和速度的提高，主轴电机的速度也在不断提升，有厂商开始采用精密机械工业的液态轴承机电技术，这种技术的应用有效地降低了硬盘工作噪音。</p><p><strong>前置控制电路</strong></p><p>前置放大电路控制磁头感应的信号、主轴电机调速、磁头驱动和伺服定位等，由于磁头读取的信号微弱，将放大电路密封在腔体内可减少外来信号的干扰，提高操作指令的准确性。</p><h4 id="逻辑结构"><a href="#逻辑结构" class="headerlink" title="逻辑结构"></a>逻辑结构</h4><p>新硬盘是不能直接使用的，必须对它进行分区进行格式化才能存储数据。经过格式化分区后，逻辑上每个盘片的每一面都会被分为磁道、扇区、柱面这几个虚拟的概念。如图所示为硬盘划分的逻辑结构图。另外，不同的硬盘中盘片数不同，一个盘片有两面，这两面都能存储数据，每一面都会对应一个磁头，习惯上将盘面数计为磁头数，用来计算硬盘容量。</p><p>扇区、磁道（或柱面）和磁头数构成了硬盘结构的基本参数，用这些参数计算硬盘的容量，其计算公式为：</p><blockquote><p>存储容量 = 磁头数 * 磁道（柱面）数 * 每道扇区数 * 每扇区字节数</p></blockquote><img src="/images/2015/disk_6.png"><p>查看 ubuntu 磁盘信息 </p><pre class=" language-shell"><code class="language-shell">sudo fdisk -l /dev/mapper/ubuntu--vg-root</code></pre><img src="/images/2015/disk_13.png"><h5 id="磁道"><a href="#磁道" class="headerlink" title="磁道"></a>磁道</h5><img src="/images/2015/disk_7.png"><p>当磁盘旋转时，磁头若保持在一个位置上，则每个磁头都会在磁盘表面划出一个圆形轨迹，这些圆形轨迹就叫磁道。磁道上的磁道是一组记录密度不同的同心圆，如图。磁表面存储器是在不同形状（如盘状、带状等）的载体上，涂有磁性材料层，工作时，靠载磁体高速运动，由磁头在磁层上进行读写操作，信息被记录在磁层上，这些信息的轨迹就是磁道。这些磁道用肉眼是根本看不到的，因为他们仅是盘面上以特殊方式磁化了的一些磁化区，磁盘上的信息便是沿着这样的轨道存放的。相邻磁道之间并不是紧挨着的，这是因为磁化单元相隔太近时磁性会产生相互影响，同时也为磁头的读写带来困难，通常盘片的一面有成千上万个磁道。</p><h5 id="扇区"><a href="#扇区" class="headerlink" title="扇区"></a>扇区</h5><img src="/images/2015/disk_8.png" width="400px"><p>分区格式化磁盘时，每个盘片的每一面都会划分很多同心圆的磁道，而且还会将每个同心圆进一步的分割为多个相等的圆弧，这些圆弧就是扇区。为什么要进行扇区的划分呢？因为，读取和写入数据的时候，磁盘会以扇区为单位进行读取和写入数据，即使电脑只需要某个扇区内的几个字节的文件，也必须一次把这几个字节的数据所在的扇区中的全部512字节的数据全部读入内存，然后再进行筛选所需数据，所以为了提高电脑的运行速度，就需要对硬盘进行扇区划分。另外，每个扇区的前后两端都会有一些特定的数据，这些数据用来构成扇区之间的界限标志，磁头通过这些界限标志来识别众多的扇区。</p><p>扇区是硬盘的最小操作单位，但扇区对于操作系统来说还是太小了，一般操作系统有自己的硬盘操作最小单位，在 linux 下一般为 4k</p><pre class=" language-shell"><code class="language-shell">xiehui@xiehui-desktop:~$ sudo tune2fs -l  /dev/mapper/ubuntu--vg-root | grep "Block size"Block size:               4096xiehui@xiehui-desktop:~$ </code></pre><h5 id="柱面"><a href="#柱面" class="headerlink" title="柱面"></a>柱面</h5><img src="/images/2015/disk_9.png" width="400px"><p>硬盘通常由一个或多个盘片构成，而且每个面都被划分为数目相等的磁道，并从外缘开始编号（即最边缘的磁道为0磁道，往里依次累加）。如此磁盘中具有相同编号的磁道会形成一个圆柱，此圆柱称为磁盘的柱面。磁盘的柱面数与一个盘面上的磁道数是相等的。由于每个盘面都有一个磁头，因此，盘面数等于总的磁头数。</p><h4 id="访盘过程"><a href="#访盘过程" class="headerlink" title="访盘过程"></a>访盘过程</h4><p>即一次访盘请求（读/写）完成过程由三个动作组成：</p><ol><li>寻道（时间）：磁头移动定位到指定磁道 </li><li>旋转延迟（时间）：等待指定扇区从磁头下旋转经过 </li><li>数据传输（时间）：数据在磁盘与内存之间的实际传输</li></ol><p>此在磁盘上读取扇区数据（一块数据）所需时间：</p><p>$T_{io} = t_{seek}+t{la}+ n * t_{wm}$</p><p>其中:</p><p>$t_{seek}$ 为寻道时间</p><p>$t_{la}$为旋转时间</p><p>$t_{wm}$ 为传输时间</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>HDD 顺序读写的性能远高于随机读写，我们需要充分利用这一特性。</p><h3 id="SSD（Solid-State-Drives）"><a href="#SSD（Solid-State-Drives）" class="headerlink" title="SSD（Solid State Drives）"></a>SSD（Solid State Drives）</h3><p>SSD 用固态电子存储芯片列阵而制成的硬盘，如图，所示为固态硬盘，它主要由控制单元和存储单元（FLASH芯片）组成。固态硬盘的接口规范和定义、功能及使用方法上与普通硬盘的完全相同，在产品外形和尺寸上与普通硬盘几乎一致。固态硬盘的存储介质分为两种，一种是采用闪存（FLASH芯片）作为存储介质，另外一种是采用DRAM作为存储介质。</p><h4 id="组成结构"><a href="#组成结构" class="headerlink" title="组成结构"></a>组成结构</h4><p>SSD 主要由主控制器，存储单元，缓存（可选），以及跟主机接口（诸如SATA，SAS, PCIe等）组成。</p><img src="/images/2015/disk_14.png"><h5 id="主控制器"><a href="#主控制器" class="headerlink" title="主控制器"></a>主控制器</h5><p>每个 SSD 都有一个控制器(controller)将存储单元连接到电脑，主控器可以通过若干个通道（channel）并行操作多块FLASH颗粒，类似 RAID0，大大提高底层的带宽。控制器是一个执行固件(firmware)代码的嵌入式处理器。主要功能如下：</p><ul><li>错误检查和纠正(ECC)</li><li>磨损平衡(Wear leveling)</li><li>坏块映射(Bad block mapping)</li><li>Read disturb(读取某个块的数据的时候会影响到相邻块的数据)管理</li><li>缓存控制</li><li>垃圾回收</li><li>加密</li></ul><h5 id="存储单元"><a href="#存储单元" class="headerlink" title="存储单元"></a>存储单元</h5><p>尽管有某些厂商推出了基于更高速的 DRAM 内存的产品，但 NAND 闪存依然最常见，占据着绝对主导地位。低端产品一般采用 MLC(multi-level cell) 甚至 TLC(Triple Level Cell) 闪存，其特点是容量大、速度慢、可靠性低、存取次数低、价格也低。高端产品一般采用 SLC(single-level cell) 闪存，其特点是技术成熟、容量小、速度快、可靠性高、存取次数高、价格也高。但是事实上，取决于不同产品的内部架构设计，速度和可靠性的差别也可以通过各种技术加以弥补甚至反转。</p><h5 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h5><p>基于 NAND 闪存的 SSD 通常带有一个基于 DRAM 的缓存，其作用与普通的机械式硬盘类似，但是还会存储一些诸如 Wear leveling 数据之类的其他数据。把数据先缓存在 DRAM 中，然后集中写入，从而减少写入次数。特例之一是 SandForce 生产的控制器，它并不含有缓存，但是性能依旧很出色，由于其结构简单，故而可以生产体积更小的 SSD，并且掉电时数据更安全。</p><h5 id="主机接口"><a href="#主机接口" class="headerlink" title="主机接口"></a>主机接口</h5><p>主机接口与控制器紧密相关，但是通常与传统的机械式硬盘相差不大，主要有以下几种：</p><ul><li>SATA</li><li>SAS</li><li>PCI-E</li><li>Fibre Channel</li><li>USB</li></ul><h4 id="存储原理"><a href="#存储原理" class="headerlink" title="存储原理"></a>存储原理</h4><p>SSD内部一般使用 NAND Flash 来作为存储介质，其逻辑结构如下：</p><img src="/images/2015/disk_15.png"><p>SSD 中一般有多个 NAND Flash，每个 NAND Flash 包含多个  Block，每个Block 包含多个 Page。由于NAND 的特性，其存取都必须以 page 为单位，即每次读写至少是一个 page，通常地，每个 page 的大小为4k或者8k。另外，NAND还有一个特性是，其只能是读或写单个 page，但不能覆盖写如某个 page，必须先要清空里面的内容，再写入。由于清空内容的电压较高，必须是以 block 为单位。因此，没有空闲的 page 时，必须要找到没有有效内容的 block，先擦写，然后再选择空闲的 page 写入。</p><p>操作系统通常将硬盘理解为一连串 512B 大小的<strong>扇区</strong>[注意：操作系统对磁盘进行一次读或写的最小单位并不是扇区，而是文件系统的<strong>块</strong>，一般为 512B/1KB/4KB 之一(也可能更大)，其具体大小在格式化时设定]，但是闪存的读写单位是 4/8/16KB 大小的<strong>页</strong>，而且闪存的擦除(又叫编程)操作是按照 128 或 256 页大小的<strong>块</strong>来操作的。更要命的是写入数据前必须要先擦除整个块，而不能直接覆盖。这完全不符合现有的、针对传统硬盘设计的文件系统的操作方式，很明显，我们需要更高级、专门针对 SSD 设计的文件系统来适应这种操作方式。但遗憾的是，目前还没有这样的文件系统。</p><p>为了兼容现有的文件系统，就出现了 FTL(闪存转换层)，它位于文件系统和物理介质之间，把闪存的操作习惯虚拟成以传统硬盘的 512B 扇区进行操作。这样，操作系统就可以按照传统的扇区方式操作，而不用担心之前说的擦除/读/写问题。一切逻辑到物理的转换，全部由 FTL 层包了。</p><p>FTL 算法，本质上就是一种逻辑到物理的映射，因此，当文件系统发送指令说要写入或者更新一个特定的逻辑扇区时，FTL 实际上写入了另一个空闲物理页，并更新映射表，再把这个页上包含的旧数据标记为无效(更新后的数据已经写入新地址了，旧地址的数据自然就无效了)。</p><p>在 SSD 中，一般会维护一个 mapping table，维护逻辑地址到物理地址的映射。每次读写时，可以通过逻辑地址直接查表计算出物理地址，与传统的机械磁盘相比，省去了寻道时间和旋转时间。</p><h4 id="读写特性"><a href="#读写特性" class="headerlink" title="读写特性"></a>读写特性</h4><p>从NAND Flash的原理可以看出，其和HDD的主要区别为</p><ul><li>定位数据快：HDD 需要经过寻道和旋转，才能定位到要读写的数据块，而 SSD 通过mapping table直接计算即可</li><li>读取速度块：HDD 的速度取决于旋转速度，而 SSD 只需要加电压读取数据，一般而言，要快于 HDD</li></ul><p>因此，在顺序读测试中，由于定位数据只需要一次，定位之后，则是大批量的读取数据的过程，此时，HDD 和SSD 的性能差距主要体现在读取速度上，HDD 能到200M左右，而普通 SSD 是其两倍。</p><p>在随机读测试中，由于每次读都要先定位数据，然后再读取，HDD 的定位数据的耗费时间很多，一般是几毫秒到十几毫秒，远远高于 SSD 的定位数据时间(一般0.1ms左右)，因此，随机读写测试主要体现在两者定位数据的速度上，此时，SSD 的性能是要远远好于 HDD 的。</p><p>对于SSD的写操作，针对不同的情况，有不同的处理流程，主要是受到 NAND Flash 的如下特性限制</p><ul><li>NAND Flash 每次写必须以 page 为单位，且只能写入空闲的 page，不能覆盖写原先有内容的page</li><li>擦除数据时，由于电压较高，只能以 block 为单位擦除</li></ul><p>SSD的写分为新写入和更新两种，处理流程不同。</p><p><strong>新写入的数据的流程</strong></p><img src="/images/2015/disk_16.png"><p>假设新写入了一个page，其流程如下：</p><ul><li>找到一个空闲page</li><li>把数据写入到空闲page中</li><li>更新mapping table</li></ul><p><strong>更新操作的流程</strong></p><img src="/images/2015/disk_17.png"><p>假设是更新了page G 中的某些字节，流程如下：</p><ul><li>由于 SSD 不能覆盖写，因此，先找到一个空闲页 H</li><li>读取 page G 中的数据到 SSD 内部的 buffer 中，把更新的字节更新到 buffer</li><li>把 buffer 中的数据写入到 H</li><li>更新 mapping table 中 G 页，置为无效页</li><li>更新 mapping table 中 H 页，添加映射关系</li></ul><p>可以看出，如果在更新操作比较多的情况下，会产生较多的无效页，类似于磁盘碎片，此时，需要SSD的over-provisioning和garbage-collection。</p><h4 id="磨损平衡"><a href="#磨损平衡" class="headerlink" title="磨损平衡"></a>磨损平衡</h4><p>简单说来，磨损平衡(Wear leveling)是确保闪存的每个块被写入的次数相等的一种机制。</p><p>通常情况下，在 NAND 块里的数据更新频度是不同的：有些会经常更新，有些则不常更新。很明显，那些经常更新的数据所占用的块会被快速的磨损掉，而不常更新的数据占用的块磨损就小得多。为了解决这个问题，需要让每个块的编程(擦写)次数尽可能保持一致：这就是需要对每个页的读取/编程操作进行监测，在最乐观的情况下，这个技术会让全盘的颗粒物理磨损程度相同并同时报废。</p><p>磨损平衡算法分静态和动态。动态磨损算法是基本的磨损算法：只有用户在使用中更新的文件占用的物理页地址被磨损平衡了。而静态磨损算法是更高级的磨损算法：在动态磨损算法的基础上，增加了对于那些不常更新的文件占用的物理地址进行磨损平衡，这才算是真正的全盘磨损平衡。简单点说来，动态算法就是每次都挑最年轻的 NAND 块来用，老的 NAND 块尽量不用。静态算法就是把长期没有修改的老数据从一个年轻 NAND 块里面搬出来，重新找个最老的 NAND 块放着，这样年轻的 NAND 块就能再度进入经常使用区。概念很简单，但实现却非常的复杂，特别是静态。</p><p>尽管磨损均衡的目的是避免数据重复在某个空间写入，以保证各个存储区域内磨损程度基本一致，从而达到延长固态硬盘的目的。但是，它对固态硬盘的性能有不利影响。</p><p>以一个例子，说明损耗均衡控制的重要性：</p><p>假如一个 NAND Flash 总共有 4096个block，每个 block 的擦写次数最大为10000。其中有3个文件，每个文件占用50个block，平均10分钟更新1个文件，假设没有均衡控制，那么只会3 * 50 + 50共200个block，则这个SSD的寿命如下：</p><img src="/images/2015/disk_18.png"><p>大约为278天。而如果是完美的损耗均衡控制，即4096个block都均衡地参与更新，则使用寿命如下：</p><img src="/images/2015/disk_19.png"><p>大约5689天。因此，设计一个好的损耗均衡控制算法是非常有必要的，主流的方法主要有两种：</p><ul><li>dynamic wear leveling</li><li>static wear leveling</li></ul><p>这里的 dynamic 和 static 是指的是数据的特性，如果数据频繁的更新，那么数据是 dynamic 的，如果数据写入后，不更新，那么是 static 的。</p><p>dynamic wear leveling 的原理是记录每个 block 的擦写次数，每次写入数据时，找到被擦除次数最小的空block。</p><p>static wear leveling 的原理分为两块：</p><ul><li>每次找到每擦除次数最小的可用 block</li><li>当某个 block 的擦除次数小于阈值时，会将它与擦写次数较高的 block 的数据进行交换</li></ul><p>以一个例子来说明，两种擦写算法的不同点：</p><p>假如 SSD 中有25%的数据是 dynamic 的，另外75%的数据是 static 的。对于 dynamic wear leveling 方法，每次要找的是擦除了数据的 block，而 static 的 block 里面是有数据的，因此，每次都只会在 dynamic 的 block 中，即最多会在25%的 block 中做均衡；对于 static 算法，每次找的 block 既可能是 dynamic 的，也可能是 static 的，因此，最多有可能在全部的 block 中做均衡。</p><p>相对而言，static 算法能使得 SSD 的寿命更长，但也有其缺点：</p><ul><li>算法逻辑更复杂</li><li>在写入时，可能会移动数据，导致写放大，降低写入性能</li><li>更高的能耗</li></ul><h4 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h4><p>由前面的磨损平衡机制知道，磨损平衡的执行需要有“空白块”来写入更新后的数据。当可以直接写入数据的“备用空白块”数量低于一个阀值后，SSD 主控制器就会把那些包含无效数据的块里的所有有效数据合并起来写到新的“空白块”中，然后擦除这个块以增加“备用空白块”的数量。这个操作就是 SSD 的垃圾回收。</p><img src="/images/2015/gc_1.jpg" width="400px"><img src="/images/2015/gc_2.jpg" width="400px"><p>有三种垃圾回收策略：</p><ol><li><p>闲置垃圾回收：很明显在进行垃圾回收时候会消耗大量的主控处理能力和带宽造成处理用户请求的性能下降，SSD 主控制器可以设置在系统闲置时候做“预先”垃圾回收(提前做垃圾回收操作)，保证一定数量的”备用空白块”，让 SSD 在运行时候能够保持较高的性能。闲置垃圾回收的缺点是会增加额外的”写入放大”，因为你刚刚垃圾回收的”有效数据”，也许马上就会被更新后的数据替代而变成”无效数据”，这样就造成之前的垃圾回收做无用功了。</p></li><li><p>被动垃圾回收：每个 SSD 都支持的技术，但是对主控制器的性能提出了很高的要求，适合在服务器里用到，SandForce 的主控就属这类。在垃圾回收操作消耗带宽和处理能力的同时处理用户操作数据，如果没有足够强劲的主控制器性能则会造成明显的速度下降。这就是为啥很多 SSD 在全盘写满一次后会出现性能下降的道理，因为要想继续写入数据就必须要边垃圾回收边做写入。</p></li><li><p>手动垃圾回收：用户自己手动选择合适的时机运行垃圾回收软件，执行垃圾回收操作。</p></li></ol><p>可以想象，如果系统经常进行垃圾回收处理，频繁的将一些区块进行擦除操作，那么 SSD 的寿命反而也会进一步下降。由此把握这个垃圾回收的频繁程度，同时确保 SSD 中的闪存芯片拥有更高的使用寿命，这确实需要找到一个完美的平衡点。所以，SSD 必须要支持 Trim 技术，不然 GC 就显不出他的优势了。</p><h4 id="Trim"><a href="#Trim" class="headerlink" title="Trim"></a>Trim</h4><p>Trim 是一个 ATA 指令，当操作系统删除文件或格式化的时候，由操作系统同时把这个文件地址发送给 SSD 的主控制器，让主控制器知道这个地址的数据无效了。</p><p>当你删除一个文件的时候，文件系统其实并不会真正去删除它，而只是把这个文件地址标记为“已删除”，可以被再次使用，这意味着这个文件占的地址已经是“无效”的了。这就会带来一个问题，硬盘并不知道操作系统把这个地址标记为“已删除”了，机械盘的话无所谓，因为可以直接在这个地址上重新覆盖写入，但是到了 SSD 上问题就来了。NAND 需要先擦除才能再次写入数据，要得到空闲的 NAND 空间，SSD 必须复制所有的有效页到新的空闲块里，并擦除旧块(垃圾回收)。如果没有 Trim 指令，意味着 SSD 主控制器不知道这个页是“无效”的，除非再次被操作系统要求覆盖上去。</p><p>Trim 只是条指令，让操作系统告诉 SSD 主控制器这个页已经“无效”了。Trim 会减少写入放大，因为主控制器不需要复制“无效”的页(没 Trim 就是“有效”的)到空白块里，这同时代表复制的“有效”页变少了，垃圾回收的效率和 SSD 性能也提升了。</p><p>Trim 能大量减少伪有效页的数量，它能大大提升垃圾回收的效率。</p><p>目前，支持 Trim 需要三个要素，缺一不可：</p><ul><li>系统： 操作系统必须会发送 Trim 指令，Win7, Win2008R2 , Linux-2.6.33 以上。</li><li>固件： SSD 的厂商在固件里要放有 Trim 算法，也就是 SSD 的主控制器必须认识 Trim 指令。</li><li>驱动： 控制器驱动必须要支持 Trim 指令的传输，也就是能够将 Trim 指令传输到 SSD 控制器。MS 的驱动，Intel 的 AHCI 驱动目前支持。别的要看之后的更新了。</li></ul><p>目前，RAID 阵列里的盘明确不支持 TRIM，不过 RAID 阵列支持 GC。</p><h4 id="NCQ"><a href="#NCQ" class="headerlink" title="NCQ"></a>NCQ</h4><p>NCQ(Native Command Queuing) 的意思是原生指令排序。使用 NCQ 技术可以对将要读取的文件进行内部排序，然后对文件的排序做最佳化线路读写，达到提升读写效率的目地。NCQ 最早是 SCSI 的标准之一，只是那时候不叫 NCQ，对这个标准稍作修改后，在 SATA 的应用上就叫做 NCQ 了，SAS 接口也支持 NCQ。SSD 虽然没有机械臂，但是 SSD 有多通道。开启 NCQ 后，SSD 主控制器会根据数据的请求和 NAND 内部数据的分布，充分利用主控制器通道的带宽达到提升性能的目地，所以 NCQ 对 SSD 也有帮助，理想状况下性能提升可达5-10倍。目前原生支持 SATA 的 SSD 都能支持 NCQ。当然，要开启NCQ，必须要使用 AHCI 模式。</p><h4 id="预留空间"><a href="#预留空间" class="headerlink" title="预留空间"></a>预留空间</h4><p>预留空间(Over-provisioning)是指用户不可操作的容量，为实际物理闪存容量减去用户可用容量。这块区域一般被用来做优化，包括磨损均衡，GC和坏块映射。</p><p>第一层为固定的7.37%，这个数字是如何得出的哪？我们知道机械硬盘和 SSD 的厂商容量是这样算的，1GB 是1,000,000,000字节(10的9 次方)，但是闪存的实际容量是每 GB=1,073,741,824，(2的30次方) ，两者相差7.37%。所以说假设1块 128GB 的 SSD，用户得到的容量是 128,000,000,000 字节，多出来的那个 7.37% 就被主控固件用做OP了。</p><p>第二层来自制造商的设置，通常为 0%，7%，28% 等，打个比方，对于 128G 颗粒的 SandForce 主控 SSD，市场上会有 120G 和 100G 两种型号卖，这个取决于厂商的固件设置，这个容量不包括之前的第一层 7.37% 。</p><p>第三层是用户在日常使用中可以分配的预留空间，用户可以在分区的时候，不分到完全的 SSD 容量来达到这个目的。不过需要注意的是，需要先做安全擦除(Secure Erase)，以保证此空间确实没有被使用过。</p><img src="/images/2015/op_1.jpg" width="400px"><p>预留空间虽然让 SSD 的可用容量小了，但是带来了减少写入放大、提高耐久性、提高性能的效果。根据经验，预留空间在 20%-35% 之间是最佳平衡点。</p><p>以一个例子，说明 SSD 的预留空间和 GC：</p><img src="/images/2015/disk_20.png"><p>如上图所示，假设系统中就两个 block，最终还剩下两个无效的 page，此时，要写入一个新 page，根据 NAND 原理，必须要先对两个无效的 page 擦除才能用于写入。此时，就需要用到 SSD 提供的额外空间，才能用 GC 方法整理出可用空间。</p><img src="/images/2015/disk_21.png" width="400px"><p>GC 的整理流程如上图所示</p><ul><li>首先，从预留空间中，找到一个空闲的 block</li><li>把 Block0 的 ABCDEFH 和 Block1 的 A 复制到空闲 block</li><li>擦除 Block0</li><li>把 Block1 的 BCDEFH  复制到Block0，此时 Block0 就有两个空闲 page 了</li><li>擦除 BLock1</li></ul><p>有空闲 page 之后，就可以按照正常的流程来写入了。</p><p>SSD 的 GC 会带来两个问题：</p><ul><li>SSD 的寿命减少，NAND Flash 中每个原件都有擦写次数限制，超过一定擦写次数后，就只能读取不能写入了</li><li>写放大问题，即内部真正写入的数据量大于用户请求写入的数据量</li></ul><p>如果频繁的在某些 block 上做 GC，会使得这些元件比其他部分更快到达擦写次数限制，因此，需要某个算法，能使得原件的擦写次数比较平均，这样才能延长 SSD 的寿命，这就需要损耗均衡控制了。</p><h4 id="写入放大"><a href="#写入放大" class="headerlink" title="写入放大"></a>写入放大</h4><p>写入放大(Write amplification)，因为闪存必须先擦除(也叫编程)才能写入，在执行这些操作的时候，移动或覆盖用户数据和元数据(metadata)不止一次。这些额外的操作，不但增加了写入数据量，减少了SSD的使用寿命，而且还吃光了闪存的带宽，间接地影响了随机写入性能。这种效应就叫写入放大(Write amplification)。一个主控的好坏主要体现在写入放大上。</p><p>比如我要写入一个 4KB 的数据，最坏的情况是，一个块里已经没有干净空间了，但是有无效数据可以擦除，所以主控就把所有的数据读到缓存，擦除块，从缓存里更新整个块的数据，再把新数据写回去。这个操作带来的写入放大就是：我实际写4K的数据，造成了整个块(1024KB)的写入操作，那就是256倍放大。同时带来了原本只需要简单的写4KB的操作变成闪存读取(1024KB)，缓存改(4KB)，闪存擦(1024KB)，闪存写(1024KB)，造成了延迟大大增加，速度急剧下降也就是自然的事了。所以，写入放大是影响 SSD 随机写入性能和寿命的关键因素。</p><p>用100%随机4KB来写入 SSD，对于目前的大多数 SSD 主控而言，在最糟糕的情况下，写入放大的实际值可能会达到或超过20倍。当然，用户也可以设置一定的预留空间来减少写入放大，假设你有个 128G 的 SSD，你只分了 64G 的区使用，那么最坏情况下的写入放大就能减少约3倍。</p><p>许多因素影响 SSD 的写入放大。下面列出了主要因素，以及它们如何影响写入放大。</p><ol><li>垃圾回收虽然增加了写入放大(被动垃圾回收不影响，闲置垃圾回收影响)，但是速度有提升。</li><li>预留空间可以减少写入放大，预留空间越大，写入放大越低。</li><li>开启 TRIM 指令后可以减少写入放大</li><li>用户使用中没有用到的空间越大，写入放大越低(需要有 Trim 支持)。</li><li>持续写入可以减少写入放大。理论上来说，持续写入的写入放大为1，但是某些因素还是会影响这个数值。</li><li>随机写入将会大大提升写入放大，因为会写入很多非连续的 LBA。</li><li>磨损平衡机制直接提高了写入放大</li></ol><h4 id="SSD-读写速度"><a href="#SSD-读写速度" class="headerlink" title="SSD 读写速度"></a>SSD 读写速度</h4><p>从软件开发人员作为 SSD 的用户角度来讲，首先需要了解的是 SSD 和普通 HDD 的性能对比，如下：</p><img src="/images/2015/disk_27.png"><p><strong>顺序读和顺序写</strong></p><p>HDD 的顺序读速度差不多为最慢的  SSD的一半，顺序写稍微好点，但也比大部分慢一倍左右的速度。</p><p><strong>随机读和随机写</strong></p><p>可以看出，HDD的随机读的性能是普通SSD的几十分之一，随机写性能更差。</p><p>因此，SSD的随机读和写性能要远远好于HDD。</p><h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>使用 SSD 时，我们需要考虑如下情况：</p><ul><li>需要充分利用其随机读写快的特性</li><li>尽可能在软件层面更新小块数据，减轻 SSD 写放大问题</li><li>避免频繁的更新数据，减轻 SSD 写放大及寿命减少的问题，尽可能使用追加的方式写数据</li></ul><h3 id="Linux测试磁盘I-O性能"><a href="#Linux测试磁盘I-O性能" class="headerlink" title="Linux测试磁盘I/O性能"></a>Linux测试磁盘I/O性能</h3><p>我们常用<code>dd</code>命令测试 Linux 磁盘 I/O 情况，<code>dd</code>只是测试顺序读写性能。对于随机读写性能测试，可采用<code>FIO</code>工具。</p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>下载并安装</p><pre class=" language-shell"><code class="language-shell">wget http://brick.kernel.dk/snaps/fio-2.2.5.tar.gzyum install libaio-devel gcc  -ytar -zxvf fio-2.2.5.tar.gzcd fio-2.2.5makemake install</code></pre><h4 id="FIO参数"><a href="#FIO参数" class="headerlink" title="FIO参数"></a>FIO参数</h4><p>随机读：</p><pre class=" language-shell"><code class="language-shell">fio -filename=/tmp/test_randread -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=16k -size=30G -numjobs=10 -runtime=60 -group_reporting -name=mytest####################说明：filename=/dev/sdb1       测试文件名称，通常选择需要测试的盘的data目录。direct=1                 测试过程绕过机器自带的buffer。使测试结果更真实。rw=randwrite             测试随机写的I/Orw=randrw                测试随机写和读的I/Obs=16k                   单次io的块文件大小为16kbsrange=512-2048         同上，提定数据块的大小范围size=5g    本次的测试文件大小为5g，以每次4k的io进行测试。numjobs=30               本次的测试线程为30.runtime=1000             测试时间为1000秒，如果不写则一直将5g文件分4k每次写完为止。ioengine=psync           io引擎使用pync方式rwmixwrite=30            在混合读写的模式下，写占30%group_reporting          关于显示结果的，汇总每个进程的信息。此外lockmem=1g               只使用1g内存进行测试。zero_buffers             用0初始化系统buffer。</code></pre><h4 id="常用测试命令"><a href="#常用测试命令" class="headerlink" title="常用测试命令"></a>常用测试命令</h4><p>随机读</p><pre class=" language-shell"><code class="language-shell">fio -filename=/tmp/test_randread -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=16k -size=30G -numjobs=10 -runtime=600 -group_reporting -name=mytest</code></pre><p>随机写</p><pre class=" language-shell"><code class="language-shell">fio -filename=/tmp/test_randread -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=16k -size=30G -numjobs=10 -runtime=600 -group_reporting -name=mytest</code></pre><p>顺序写</p><pre class=" language-shell"><code class="language-shell">fio -filename=/data/test_randread -direct=1 -iodepth 1 -thread -rw=write -ioengine=psync -bs=16k -size=30G -numjobs=10 -runtime=600 -group_reporting -name=mytest</code></pre><p>顺序读</p><pre class=" language-shell"><code class="language-shell">fio -filename=/tmp/test_randread -direct=1 -iodepth 1 -thread -rw=read -ioengine=psync -bs=16k -size=30G -numjobs=10 -runtime=60 -group_reporting -name=mytest</code></pre><p>混合随机读写</p><pre class=" language-shell"><code class="language-shell">fio -filename=/tmp/test_randread -direct=1 -iodepth 1 -thread -rw=randrw -rwmixread=70 -ioengine=psync -bs=16k -size=30G -numjobs=10 -runtime=600 -group_reporting -name=mytest -ioscheduler=noop</code></pre><h4 id="IOPS-和-吞吐量"><a href="#IOPS-和-吞吐量" class="headerlink" title="IOPS 和 吞吐量"></a><strong>IOPS 和 吞吐量</strong></h4><p>为何随机是关注IOPS，顺序关注吞吐量？</p><p>因为随机读写的话，每次IO操作的寻址时间和旋转延时都不能忽略不计，而这两个时间的存在也就限制了IOPS的大小；而顺序读写可以忽略不计寻址时间和旋转延时，主要花费在数据传输的时间上。</p><h2 id="分层详解"><a href="#分层详解" class="headerlink" title="分层详解"></a>分层详解</h2><img src="/images/2015/Linux.IO.stack_v1.0.png"><p>程序处理文件的目的就是把数据写到磁盘或者从磁盘把数据读取到内存中, 我们先用程序将数据写入到磁盘中：</p><pre class=" language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">include</span>  <span class="token string">&lt;stdio.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span>  <span class="token string">&lt;stdlib.h></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span><span class="token keyword">char</span> <span class="token operator">*</span>argv<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    FILE <span class="token operator">*</span>fp1<span class="token punctuation">,</span> <span class="token operator">*</span>fp2<span class="token punctuation">;</span>       <span class="token comment" spellcheck="true">//流指针</span>    <span class="token keyword">char</span> buf<span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">//缓冲区</span>    <span class="token keyword">int</span> n<span class="token punctuation">;</span>                 <span class="token comment" spellcheck="true">//存放fread和fwrite函数的返回值</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>argc <span class="token operator">&lt;=</span><span class="token number">2</span><span class="token punctuation">)</span>            <span class="token punctuation">{</span>       <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"请输入正确的参数\n!"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token punctuation">}</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>fp1 <span class="token operator">=</span> <span class="token function">fopen</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">(</span>argv<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"rb"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token constant">NULL</span><span class="token punctuation">)</span>    <span class="token punctuation">{</span>         <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"读源文件%s发生错误\n"</span><span class="token punctuation">,</span><span class="token operator">*</span><span class="token punctuation">(</span>argv<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token keyword">return</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>fp2 <span class="token operator">=</span> <span class="token function">fopen</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">(</span>argv<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"wb"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token constant">NULL</span><span class="token punctuation">)</span>    <span class="token punctuation">{</span>         <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"打开目标文件%s失败\n"</span><span class="token punctuation">,</span><span class="token operator">*</span><span class="token punctuation">(</span>argv<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token keyword">return</span> <span class="token number">2</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>n <span class="token operator">=</span> <span class="token function">fread</span><span class="token punctuation">(</span>buf<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">char</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> fp1<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span>    <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">fwrite</span><span class="token punctuation">(</span>buf<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">char</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n<span class="token punctuation">,</span> fp2<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token punctuation">{</span>            <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"写入文件发生错误\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">return</span> <span class="token number">3</span><span class="token punctuation">;</span>          <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"从源文件%s读数据写入目标文件%s中完成\n"</span><span class="token punctuation">,</span><span class="token operator">*</span><span class="token punctuation">(</span>argv<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">*</span><span class="token punctuation">(</span>argv<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//输出对应的提示</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>n <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token punctuation">{</span>         <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"读文件发生错误\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token keyword">return</span> <span class="token number">4</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token function">fclose</span><span class="token punctuation">(</span>fp1<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">fclose</span><span class="token punctuation">(</span>fp2<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>文件先写入应用程序 buffer；调用<code>fwrite</code>后，把数据从 buffer 拷贝到了 CLib buffer，即C库标准 IO buffer。<code>fwrite</code>返回后，数据还在 CLib buffer，如果这时候进程 crash 掉，这些数据会丢失。没有写到磁盘介质上。当调用<code>fclose</code>的时候，<code>fclose</code>调用会把这些数据刷新到磁盘介质上。除了<code>fclose</code>方法外，还有一个主动刷新操作<code>fflush</code>函数，不过<code>fflush</code>函数只是把数据从 CLib buffer 拷贝到 page  cache 中，并没有刷新到磁盘上，从 page cache 刷新到磁盘上可以通过调用<code>fsync</code>函数完成。</p><p>当进程 crash 时如果数据还处在应用 cache 或 CLib cache 时候，数据会丢失。如果数据在 page cache，进程crash 掉，即使数据还没有到硬盘。数据也不会丢失。当内核 crash 掉后，只要数据没有到达 disk cache，数据都会丢失。</p><h3 id="Linux-File-I-O"><a href="#Linux-File-I-O" class="headerlink" title="Linux File I/O"></a>Linux File I/O</h3><p>Linux 给我们提供各种风格的 IO 接口来使用：</p><ul><li>Syscalls: <a href="http://man7.org/linux/man-pages/man2/open.2.html" target="_blank" rel="noopener">open</a>, <a href="http://man7.org/linux/man-pages/man2/write.2.html" target="_blank" rel="noopener">write</a>, <a href="http://man7.org/linux/man-pages/man2/read.2.html" target="_blank" rel="noopener">read</a>, <a href="http://man7.org/linux/man-pages/man2/fsync.2.html" target="_blank" rel="noopener">fsync</a>, <a href="http://man7.org/linux/man-pages/man2/sync.2.html" target="_blank" rel="noopener">sync</a>, <a href="http://man7.org/linux/man-pages/man2/close.2.html" target="_blank" rel="noopener">close</a></li><li>Standard I/O: <a href="https://linux.die.net/man/3/fopen" target="_blank" rel="noopener">fopen</a>, <a href="https://linux.die.net/man/3/fwrite" target="_blank" rel="noopener">fwrite</a>, <a href="https://linux.die.net/man/3/fread" target="_blank" rel="noopener">fread</a>, <a href="https://linux.die.net/man/3/fflush" target="_blank" rel="noopener">fflush</a>, <a href="https://linux.die.net/man/3/fclose" target="_blank" rel="noopener">fclose</a></li><li>Vectored I/O: <a href="https://linux.die.net/man/2/writev" target="_blank" rel="noopener">writev</a>, <a href="https://linux.die.net/man/2/readv" target="_blank" rel="noopener">readv</a></li><li>Memory mapped I/O: <a href="http://man7.org/linux/man-pages/man2/open.2.html" target="_blank" rel="noopener">open</a>, <a href="http://man7.org/linux/man-pages/man2/mmap.2.html" target="_blank" rel="noopener">mmap</a>, <a href="http://man7.org/linux/man-pages/man2/msync.2.html" target="_blank" rel="noopener">msync</a>, <a href="http://man7.org/linux/man-pages/man2/munmap.2.html" target="_blank" rel="noopener">munmap</a></li></ul><h4 id="标准-I-O（Standard-I-O）"><a href="#标准-I-O（Standard-I-O）" class="headerlink" title="标准 I/O（Standard I/O）"></a>标准 I/O（Standard I/O）</h4><h5 id="缓存-I-O"><a href="#缓存-I-O" class="headerlink" title="缓存 I/O"></a>缓存 I/O</h5><img src="/images/2015/disk_28.png" width="400px"><p>大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。缓存 I/O 有以下这些优点：</p><ul><li>缓存 I/O 使用了操作系统内核缓冲区，在一定程度上分离了应用程序空间和实际的物理设备。</li><li>缓存 I/O 可以减少读盘的次数，从而提高性能。</li></ul><p>标准IO通过系统调用 <code>read()</code> 和 <code>write()</code> 执行 IO 操作。当应用程序尝试读取某块数据的时候，如果这块数据已经存放在了 Page Cache 中，那么这块数据就可以立即返回给应用程序，而不需要经过实际的物理读盘操作。当然，如果数据在应用程序读取之前并未被存放在页缓存中，则会触发<em>*Page Fault</em> **然后将数据从磁盘读到 Page Cache 中去。对于写操作来说，应用程序也会将数据先写到 Page Cache 中去，数据是否被立即写到磁盘上去取决于应用程序所采用的写操作机制：如果用户采用的是同步写机制（ synchronous writes ）, 那么数据会立即被写回到磁盘上，应用程序会一直等到数据被写完为止；如果用户采用的是延迟写机制（ deferred writes ），那么应用程序就完全不需要等到数据全部被写回到磁盘，数据只要被写到 Page Cache 中去就可以了。在延迟写机制的情况下，操作系统会定期地将放在 Page Cache 中的数据刷到磁盘上。与异步写机制（ asynchronous writes ）不同的是，延迟写机制在数据完全写到磁盘上的时候不会通知应用程序，而异步写机制在数据完全写到磁盘上的时候是会返回给应用程序的。所以延迟写机制本身是存在数据丢失的风险的，而异步写机制则不会有这方面的担心。</p><p><strong>缓存 I/O 的缺点</strong></p><p>在缓存 I/O 机制中，DMA 方式可以将数据直接从磁盘读到页缓存中，或者将数据从页缓存直接写回到磁盘上，而不能直接在应用程序地址空间和磁盘之间进行数据传输，这样的话，数据在传输过程中需要在应用程序地址空间和页缓存之间进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。</p><p>对于某些特殊的应用程序来说，避开操作系统内核缓冲区而直接在应用程序地址空间和磁盘之间传输数据会比使用操作系统内核缓冲区获取更好的性能。</p><h5 id="直接-I-O"><a href="#直接-I-O" class="headerlink" title="直接 I/O"></a>直接 I/O</h5><img src="/images/2015/disk_29.png" width="400px"><p>凡是通过直接 I/O 方式进行数据传输，数据均直接在用户地址空间的缓冲区和磁盘之间直接进行传输，完全不需要页缓存的支持。操作系统层提供的缓存往往会使应用程序在读写数据的时候获得更好的性能，但是对于某些特殊的应用程序，比如说数据库系统，它们更倾向于选择他们自己的缓存机制，因为数据库系统往往比操作系统更了解数据库中存放的数据，数据库系统可以提供一种更加有效的缓存机制来提高数据库中数据的存取性能。</p><p>要在块设备中执行直接 I/O，进程必须在打开文件的时候设置对文件的访问模式为 <code>O_DIRECT</code>，这样就等于告诉操作系统进程在接下来使用 <code>read()</code> 或者 <code>write()</code> 系统调用去读写文件的时候使用的是直接 I/O 方式，所传输的数据均不经过操作系统内核缓存空间。使用直接 I/O 读写数据必须要注意缓冲区对齐（ buffer alignment ）以及缓冲区的大小的问题，即对应 <code>read()</code> 以及 <code>write()</code> 系统调用的第二个和第三个参数。这里边说的对齐指的是文件系统块大小的对齐，缓冲区的大小也必须是该块大小的整数倍。</p><p><strong>直接 I/O 的优点</strong></p><p>直接 I/O 最主要的优点就是通过减少操作系统内核缓冲区和应用程序地址空间的数据拷贝次数，降低了对文件读取和写入时所带来的 CPU 的使用以及内存带宽的占用。这对于某些特殊的应用程序，比如自缓存应用程序来说，不失为一种好的选择。如果要传输的数据量很大，使用直接 I/O 的方式进行数据传输，而不需要操作系统内核地址空间拷贝数据操作的参与，这将会大大提高性能。<code>O_DIRECT</code> 特别适用于数据库系统这类应用。</p><p><strong>直接 I/O 潜在可能存在的问题</strong></p><p>直接 I/O 并不一定总能提供令人满意的性能上的飞跃。设置直接 I/O 的开销非常大，而直接 I/O 又不能提供缓存 I/O 的优势。缓存 I/O 的读操作可以从高速缓冲存储器中获取数据，而直接 I/O 的读数据操作会造成磁盘的同步读，这会带来性能上的差异 , 并且导致进程需要较长的时间才能执行完；对于写数据操作来说，使用直接 I/O 需要 <code>write()</code> 系统调用同步执行，否则应用程序将会不知道什么时候才能够再次使用它的 I/O 缓冲区。与直接 I/O 读操作类似的是，直接 I/O 写操作也会导致应用程序关闭缓慢。所以，应用程序使用直接 I/O 进行数据传输的时候通常会和使用异步 I/O 结合使用。</p><blockquote><p>引用Linus的话：” The thing that has always disturbed me about O_DIRECT is that the whole interface is just stupid, and was probably designed by a deranged monkey on some serious mind-controlling substances.”—Linus（O_DIRECT 就是傻逼设计）</p></blockquote><p><strong>实例</strong></p><ol><li>打开文件时，添加<code>O_DIRECT</code>参数，需要定义<code>_GNU_SOURCE</code>，否则找不到<code>O_DIRECT</code>宏定义</li></ol><pre class=" language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">define</span> _GNU_SOURCE</span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;sys/types.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;sys/stat.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;fcntl.h></span></span><span class="token keyword">int</span> fd <span class="token operator">=</span> <span class="token function">open</span><span class="token punctuation">(</span><span class="token string">"test.out"</span><span class="token punctuation">,</span> O_RDWR <span class="token operator">|</span> O_CREAT <span class="token operator">|</span> O_DIRECT<span class="token punctuation">,</span> <span class="token number">0644</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><ol start="2"><li><p>读写操作的传输数据大小和缓冲区地址都需要按照一定的规则对齐,对于不同的文件系统和内核版本，需要的对齐边界不同，也没有统一的接口可以获取到该边界值。</p><ul><li><p>对于 kernel 2.4 版本：传输大小和缓冲区地址均需要按照访问文件系统的逻辑块大小对齐，比如文件系统的块大小是4K，buffer 地址需要按照4K对齐，需要读写4K倍数的数据</p></li><li><p>对于 kernel 2.6 版本：传输大小和缓冲区地址按照目标存储设备的扇区大小（一般512）对齐</p></li></ul><p>可使用<code>memalign （malloc.h）</code>来分配指定地址对齐的资源接口：<code>void *memalign(size_t boundary, size_t size)</code>;</p></li></ol><pre class=" language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">define</span> _GNU_SOURCE</span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;sys/types.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;fcntl.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;malloc.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;stdio.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;errno.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;string.h></span></span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">char</span> hello_str<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"Hello World!"</span><span class="token punctuation">;</span>        <span class="token keyword">void</span> <span class="token operator">*</span>write_buffer<span class="token punctuation">;</span>        <span class="token keyword">void</span> <span class="token operator">*</span>read_buffer<span class="token punctuation">;</span>        <span class="token keyword">int</span> fd<span class="token punctuation">;</span>         <span class="token keyword">int</span> ret <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        fd <span class="token operator">=</span> <span class="token function">open</span><span class="token punctuation">(</span><span class="token string">"test.out"</span><span class="token punctuation">,</span> O_RDWR <span class="token operator">|</span> O_CREAT <span class="token operator">|</span> O_DIRECT<span class="token punctuation">,</span> <span class="token number">0644</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>fd <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"Failed to open file\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">return</span> fd<span class="token punctuation">;</span>         <span class="token punctuation">}</span>           <span class="token comment" spellcheck="true">/* allocate a 1024 bytes buffer */</span>        write_buffer <span class="token operator">=</span> <span class="token function">memalign</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// align by 512</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>write_buffer<span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"Failed to alloc write buffer\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                ret <span class="token operator">=</span> <span class="token operator">-</span>ENOMEM<span class="token punctuation">;</span>                <span class="token keyword">goto</span> bad_write_buffer<span class="token punctuation">;</span>        <span class="token punctuation">}</span>           <span class="token function">memcpy</span><span class="token punctuation">(</span>write_buffer<span class="token punctuation">,</span> hello_str<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>hello_str<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        ret <span class="token operator">=</span> <span class="token function">write</span><span class="token punctuation">(</span>fd<span class="token punctuation">,</span> write_buffer<span class="token punctuation">,</span> <span class="token number">512</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>         <span class="token keyword">if</span> <span class="token punctuation">(</span>ret <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"Failed to write file\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                 <span class="token keyword">goto</span> bad_write<span class="token punctuation">;</span>        <span class="token punctuation">}</span>           <span class="token function">lseek</span><span class="token punctuation">(</span>fd<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> SEEK_SET<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// read  previous write data</span>        read_buffer <span class="token operator">=</span> <span class="token function">memalign</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>read_buffer<span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"Failed to alloc read buffer\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                ret <span class="token operator">=</span> <span class="token operator">-</span>ENOMEM<span class="token punctuation">;</span>                <span class="token keyword">goto</span> bad_read_buffer<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        ret <span class="token operator">=</span> <span class="token function">read</span><span class="token punctuation">(</span>fd<span class="token punctuation">,</span> read_buffer<span class="token punctuation">,</span> <span class="token number">512</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>ret <span class="token operator">&lt;</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"Failed to read file\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">goto</span> bad_read<span class="token punctuation">;</span>        <span class="token punctuation">}</span>        <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"read from file : %s\n"</span><span class="token punctuation">,</span> read_buffer<span class="token punctuation">)</span><span class="token punctuation">;</span>bad_read<span class="token punctuation">:</span>        <span class="token function">free</span><span class="token punctuation">(</span>read_buffer<span class="token punctuation">)</span><span class="token punctuation">;</span>bad_read_buffer<span class="token punctuation">:</span>bad_write<span class="token punctuation">:</span>        <span class="token function">free</span><span class="token punctuation">(</span>write_buffer<span class="token punctuation">)</span><span class="token punctuation">;</span>bad_write_buffer<span class="token punctuation">:</span>        <span class="token function">close</span><span class="token punctuation">(</span>fd<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> ret<span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>O_DIRECT的详细描述，可以看linux open系统调用的<a href="http://man7.org/linux/man-pages/man2/open.2.html" target="_blank" rel="noopener">文档</a></p><h4 id="AIO"><a href="#AIO" class="headerlink" title="AIO"></a>AIO</h4><p>Asynchronous I/O 帮助用户程序提高 CPU 和 IO 设备的利用率和提高程序性能，特别是在高负载的IO操作下。比如各种代理服务器，数据库，流服务器等等。</p><p>很多人会将 AIO 理解成磁盘 IO 的异步方案，会将 AIO 狭隘化为类 epoll 接口在磁盘 IO 的特殊化，其实 AIO 应该是横架于整个内核的接口，它把所有的 IO 包括(本地设备，网络，管道等)以统一的异步接口提供给用户程序，每个子系统都针对接口实现自己的异步方案，而同步IO(Synchronous IO)只是在内核内部的”AIO+Blocking”.</p><img src="/images/2015/disk_31.png" width="400px"><h5 id="Linux-Native-Aio"><a href="#Linux-Native-Aio" class="headerlink" title="Linux Native Aio"></a>Linux Native Aio</h5><p>由操作系统内核提供的AIO，头文件为<code>&lt;linux/aio_abi.h&gt;</code>。Native Aio 是真正的 AIO，完全非阻塞异步的，而不是用阻塞IO和线程池模拟。主要的几个系统调用为<code>io_submit/io_setup/io_getevents</code>。</p><ul><li><strong>优点</strong>：由操作系统提供，读写操作可以直接投递到硬件，不会浪费 CPU。</li><li><strong>缺点</strong>：仅支持 Linux，必须使用 Direct_IO，所以无法利用到操作系统的 Page Cache。对于写文件来说native aio 的作用不大，应为本身写文件就是先写到 PageCache 上，直接返回，没有 IO 等待。</li></ul><h5 id="GCC-AIO"><a href="#GCC-AIO" class="headerlink" title="GCC AIO"></a>GCC AIO</h5><p>gcc 遵循 posix 标准实现了AIO。头文件为 <code>&lt;aio.h&gt;</code>，支持 FreeBSD/Linux。是通过阻塞 IO+线程池来实现的。主要的几个函数是<code>aio_read/aio_write/aio_return</code>。</p><ul><li><strong>优点</strong>：支持平台多，兼容性好，无需依赖第三方库，阻塞 IO 可以利用到操作系统的 Page Cache。</li><li><strong>缺点</strong>：据说有一些 bug 和陷阱，一直未解决。</li></ul><h5 id="Libeio"><a href="#Libeio" class="headerlink" title="Libeio"></a>Libeio</h5><p>libev 的作者开发的 AIO 实现，与 gcc aio 类似也是使用阻塞IO+线程池实现的。优点与缺点参见上面。它与gcc aio 的不同之处，代码更简洁，所以 bug 少更安全稳定。但这是一个第三方库，你的代码需要依赖 libeio。</p><h4 id="Vectored-IO"><a href="#Vectored-IO" class="headerlink" title="Vectored IO"></a>Vectored IO</h4><img src="/images/2015/disk_32.png" width="400px"><p> Vectored IO（也称为Scatter / Gather）是一种可以在单次系统调用中对多个缓冲区输入输出的方法，可以把多个缓冲区的数据写到单个数据流，也可以把单个数据流读到多个缓冲区中。其命名的原因在于数据会被分散到指定缓冲区向量，或者从指定缓冲区向量中聚集数据。这种输入输出方法也称为向量 I/O（vector I/O）。与之不同，标准读写系统调用（read，write）可以称为线性I/O（linear I/O）。</p><p>与线性 I/O 相比，分散/聚集 I/O 有如下几个优势：</p><ol><li><p>编码模式更自然</p><ul><li>如果数据本身是分段的（比如预定义的结构体的变量），向量 I/O 提供了直观的数据处理方式。</li></ul></li><li><p>效率更高</p><ul><li>单个向量 I/O 操作可以取代多个线性 I/O 操作。</li></ul></li><li><p>性能更好</p><ul><li>除了减少了发起的系统调用次数，通过内部优化，向量 I/O 可以比线性 I/O 提供更好的性能。</li></ul></li><li><p>支持原子性</p><ul><li>和多个线性 I/O 操作不同，一个进程可以执行单个向量 I/O 操作，避免了和其他进程交叉操作的风险。</li></ul></li></ol><p>Linux实现了 POSIX 1003.1-2001 中定义的一组实现 Scatter / Gather I/O 机制的系统调用。该实现满足了上面所述的所有特性。</p><p><code>readv()</code> 函数从文件描述符 fd 中读取 count 个段 (segment) (一个段即一个 iovec 结构体）到参数 iov 所指定的缓冲区中：</p><pre class=" language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;sys/uio.h></span></span>ssize_t <span class="token function">readv</span> <span class="token punctuation">(</span><span class="token keyword">int</span> fd<span class="token punctuation">,</span><span class="token keyword">const</span> <span class="token keyword">struct</span> iovec <span class="token operator">*</span>iov<span class="token punctuation">,</span><span class="token keyword">int</span> count<span class="token punctuation">)</span></code></pre><p>write() 函数从参数 iov 指定的缓冲区中读取 count 个段的数据，并写入 fd 中：</p><pre class=" language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;sys/uio.h></span></span>ssize_t <span class="token function">writev</span><span class="token punctuation">(</span><span class="token keyword">int</span> fd<span class="token punctuation">,</span><span class="token keyword">const</span> <span class="token keyword">struct</span> iovec <span class="token operator">*</span>iov<span class="token punctuation">,</span><span class="token keyword">int</span> count<span class="token punctuation">)</span></code></pre><p> 除了同时操作多个缓冲区外，readv() 函数和 writev() 函数的功能分别和 read()，write() 的功能一致。</p><p>每个 iovec 结构体描述一个独立的，物理不连续的缓冲区，我们称其为段(segment)：</p><pre class=" language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;sys/uio.h></span></span><span class="token keyword">struct</span> iovec <span class="token punctuation">{</span>   <span class="token keyword">void</span>      <span class="token operator">*</span>iov_base<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/* pointer to start of buffer */</span>   size_t   iov_len<span class="token punctuation">;</span><span class="token comment" spellcheck="true">/* size of buffer in bytes */</span><span class="token punctuation">}</span><span class="token punctuation">;</span></code></pre><p>一组段的集合称为向量(vector)。每个段描述了内存中所要读写的缓冲区的地址和长度。readv() 函数在处理下个缓冲区之前，会填满当前缓冲区的 iov_len 个字节。write() 函数在处理下个缓冲区之前，会把当前缓冲区所有 iov_len 个字节数据输出，这两个函数都会顺序处理向量中的段，从 iov[0] 开始，接着是 iov[1]，一直到 iov[count - 1] 。</p><p>目前只有很少的数据库使用 Vectored IO，毕竟它们要处理很多文件，关注延时，按块访问和缓存，而分析型或列式数据库比较适合使用 Vectored IO，比如： <a href="https://github.com/apache/arrow/blob/master/java/memory/src/main/java/io/netty/buffer/ArrowBuf.java#L26-L27" target="_blank" rel="noopener">Apache Arrow</a>。</p><h4 id="Memory-Mapping"><a href="#Memory-Mapping" class="headerlink" title="Memory Mapping"></a>Memory Mapping</h4><img src="/images/2015/disk_30.png" width="400px"><p> Linux 中内存区域（ memory region ）是可以跟一个普通的文件或者块设备文件的某一个部分关联起来的，若进程要访问内存页中某个字节的数据，操作系统就会将访问该内存区域的操作转换为相应的访问文件的某个字节的操作。Linux 中提供了系统调用 <code>mmap()</code> 来实现这种文件访问方式。与标准的访问文件的方式相比，内存映射方式可以减少标准访问文件方式中 <code>read()</code> 系统调用所带来的数据拷贝操作，即减少数据在用户地址空间和操作系统内核地址空间之间的拷贝操作。映射通常适用于较大范围，对于相同长度的数据来讲，映射所带来的开销远远低于 CPU 拷贝所带来的开销。当大量数据需要传输的时候，采用内存映射方式去访问文件会获得比较好的效率。数据库引擎中大量采用 mmap 的方式。</p><p>用户调用<code>mmap</code>将文件映射到内存时，内核进行一系列的参数检查，然后创建对应的<code>vma</code>，然后给该<code>vma</code>绑定<code>vma_ops</code>。当用户访问到<code>mmap</code>对应的内存时，CPU会触发<code>page fault</code>，在<code>page fault</code>回调中，将申请<code>pagecache</code>中的匿名页，读取文件到其物理内存中，然后将<code>pagecache</code>中所属的物理页与用户进程的<code>vma</code>进行映射。</p><p>其整个内核逻辑流程可以用下图来表示:</p><img src="/images/2015/disk_33.png"><h3 id="Page-Cache"><a href="#Page-Cache" class="headerlink" title="Page Cache"></a>Page Cache</h3><p>引入<code>Cache</code> 层的目的是为了提高 Linux 对磁盘访问的性能。Cache 层在内存中缓存了磁盘上的部分数据。当数据的请求到达时，如果在 Cache 中存在该数据且是最新的，则直接将数据传递给用户程序，免除了对底层磁盘的操作，提高了性能。Cache 层也正是磁盘 IOPS 为什么能突破200的主要原因之一。</p><p>在 Linux 的实现中，文件 Cache 分为两个层面，一是 Page Cache，另一个 Buffer Cache，每一个 Page Cache 包含若干 Buffer Cache。Page Cache 主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有<code>read/write</code>操作的时候。Buffer Cache 则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。</p><p>磁盘 Cache 有两大功能：预读和回写。预读其实就是利用了局部性原理，具体过程是：对于每个文件的第一个读请求，系统读入所请求的页面并读入紧随其后的少数几个页面（通常是三个页面），这时的预读称为同步预读。对于第二次读请求，如果所读页面不在 Cache 中，即不在前次预读的页中，则表明文件访问不是顺序访问，系统继续采用同步预读；如果所读页面在 Cache 中，则表明前次预读命中，操作系统把预读页的大小扩大一倍，此时预读过程是异步的，应用程序可以不等预读完成即可返回，只要后台慢慢读页面即可，这时的预读称为异步预读。任何接下来的读请求都会处于两种情况之一：第一种情况是所请求的页面处于预读的页面中，这时继续进行异步预读；第二种情况是所请求的页面处于预读页面之外，这时系统就要进行同步预读。</p><p>回写是通过暂时将数据存在 Cache 里，然后统一异步写到磁盘中。通过这种异步的数据I/O模式解决了程序中的计算速度和数据存储速度不匹配的鸿沟，减少了访问底层存储介质的次数，使存储系统的性能大大提高。Linux 2.6.32内核之前，采用 pdflush 机制来将脏页真正写到磁盘中，什么时候开始回写呢？下面两种情况下，脏页会被写回到磁盘：</p><ol><li>在空闲内存低于一个特定的阈值时，内核必须将脏页写回磁盘，以便释放内存。</li><li>当脏页在内存中驻留超过一定的阈值时，内核必须将超时的脏页写会磁盘，以确保脏页不会无限期地驻留在内存中。</li></ol><p>回写开始后，pdflush 会持续写数据，直到满足以下两个条件：</p><ol><li>已经有指定的最小数目的页被写回到磁盘。</li><li>空闲内存页已经回升，超过了阈值。</li></ol><p>Linux 2.6.32 内核之后，放弃了原有的 pdflush 机制，改成了 bdi_writeback  机制。bdi_writeback 机制主要解决了原有 fdflush 机制存在的一个问题：在多磁盘的系统中，pdflush 管理了所有磁盘的 Cache，从而导致一定程度的 I/O 瓶颈。bdi_writeback 机制为每个磁盘都创建了一个线程，专门负责这个磁盘的 Page Cache 的刷新工作，从而实现了每个磁盘的数据刷新在线程级的分离，提高了 I/O 性能。</p><p>回写机制存在的问题是回写不及时引发数据丢失（可由<code>sync|fsync</code>解决），回写期间读 I/O 性能很差。</p><p>详细的分析可以参见：<a href="/assets/book/linux/Linux.Kernel.Cache.pdf">Linux内核文件Cache 机制</a>、<a href="/assets/book/linux/Linux.Kernel.Delay.Write.pdf">Linux内核延迟写机制</a></p><h4 id="Page-Cache-优化"><a href="#Page-Cache-优化" class="headerlink" title="Page Cache 优化"></a>Page Cache 优化</h4><h5 id="fadvise"><a href="#fadvise" class="headerlink" title="fadvise"></a>fadvise</h5><p>在典型的 I/O 密集型的数据库服务器如 MySQL 中，会涉及到大量的文件读写，通常这些文件都是通过 buffer io 来使用的，以便充分利用到 Linux的 Page Cache。</p><p>Buffer I/O 的特点是读的时候，先检查页缓存里面是否有需要的数据，如果没有就从设备读取，返回给用户的同时，加到缓存一份;写的时候，直接写到缓存去，再由后台的进程定期刷到磁盘去。这样的机制看起来非常的好，在实践中也效果很好。</p><p>但是如果你的 I/O 非常密集，就会出现问题。首先由于 pagesize 是4K，内存的利用效率比较低。其次缓存的淘汰算法很简单，由操作系统自主进行，用户不大好参与。当你的写很多，超过系统内存的某个上限的时候，后台的进程(swapd)要出来回收页面，而且一旦回收的速度小于写入的速度，就会出现不可预期的行为。<br><strong>这里面最大的问题是：当你使用的内存包括缓存，没超过操作系统规定的上限的时候，操作系统选择不作为，让用户充分使用缓存，从它的角度来看这样效率最高。但是正是由于这种策略在实践中会导致问题。</strong></p><p>比如说MySQL服务器，我们可以把数据直接走 direct IO ,但是它的日志是走 bufferio 的。因为走 directio 需要对写入文件的偏移和大小都要扇区对全，这对日志系统来讲太麻烦了。由于 MySQL 是基于事务的，会涉及到大量的日志动作，频繁的写入，然后 <code>fsync</code> 日志一旦写入磁盘，buffer page 就没用了，但是一直会在内存呆着，直到达到内存上限，引起操作系统突然大量回收页面，出现 IO 柱塞或者内存交换等负面问题。</p><p>那么我们知道了困境在哪里，我们可以主动避免这个现象的发生。有二种方法：</p><ol><li>日志也走 direct io ,需要规模的修改 MySQL 代码，如 percona 就这么做了，提供相应的 patch。</li><li>日志还是走 buffer io, 但是定期清除无用 Page Cache.</li></ol><p>第一张方法不是我们要讨论的，我们重点讨论第二种如何做：</p><p>我们在程序里知道文件的句柄，是不是就可以很轻松的用：</p><pre class=" language-c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">posix_fadvise</span><span class="token punctuation">(</span><span class="token keyword">int</span> fd<span class="token punctuation">,</span> off_t offset<span class="token punctuation">,</span> off_t len<span class="token punctuation">,</span> <span class="token keyword">int</span> advice<span class="token punctuation">)</span><span class="token punctuation">;</span>POSIX_FADV_DONTNEEDThe specified data will not be accessed in the near future<span class="token punctuation">.</span></code></pre><p>来解决问题呢？<br>比如写类似 <code>posix_fadvise(fd, 0, len_of_file, POSIX_FADV_DONTNEED)</code>；这样的代码来清掉文件所属的缓存。但是你会发现内存根本就没下来, <strong>为什么相关的内存没有被释放出来：页面还脏是最关键的因素。</strong></p><p>但是我们如何保证页面全部不脏呢？<code>fdatasync</code>或者<code>fsync</code>都是选择, 或者 Linux 下新系统调用<code>sync_file_range</code>都是可用的，这几个都是使用<code>WB_SYNC_ALL</code>模式强制要求回写完毕才返回的。<br>如这样做：</p><pre class=" language-C"><code class="language-C">`fdatasync(fd);`</code></pre><h5 id="mlock-文件预热"><a href="#mlock-文件预热" class="headerlink" title="mlock/文件预热"></a>mlock/文件预热</h5><p>使用 <code>mlock</code> 可以将进程使用的部分或者全部的地址空间锁定在物理内存中，防止其被交换到 swap 空间。对于高吞吐量的分布式消息队列来说，追求的是消息读写低延迟，那么肯定希望尽可能地多使用物理内存，提高数据读写访问的操作效率。</p><p>文件预热的目的主要有两点：</p><ol><li>由于仅分配内存并进行<code>mlock</code>系统调用后并不会为程序完全锁定这些内存，因为其中的分页可能是写时复制的。因此，就有必要对每个内存页面中写入一个假的值。比如：RocketMQ 是在创建并分配MappedFile 的过程中，预先写入一些随机值至<code>mmap</code>映射出的内存空间里。</li><li>调用<code>mmap</code>进行内存映射后，OS 只是建立虚拟内存地址至物理地址的映射表，而实际并没有加载任何文件至内存中。程序要访问数据时OS会检查该部分的分页是否已经在内存中，如果不在，则发出一次缺页中断。这里，可以想象下1G的 CommitLog 需要发生多少次缺页中断，才能使得对应的数据才能完全加载至物理内存中。RocketMQ 的做法是，在做<code>mmap</code>内存映射的同时进行<code>madvise</code>系统调用，目的是使 OS 做一次内存映射后对应的文件数据尽可能多的预加载至内存中，从而达到内存预热的效果。</li></ol><h3 id="虚拟文件系统（VFS-）"><a href="#虚拟文件系统（VFS-）" class="headerlink" title="虚拟文件系统（VFS ）"></a>虚拟文件系统（VFS ）</h3><img src="/images/2015/disk_34.png" width="400px"><p>VFS（Virtual File System）虚拟文件系统是一种软件机制，更确切的说扮演着文件系统管理者的角色，与它相关的数据结构只存在于物理内存当中。它的作用是：屏蔽下层具体文件系统操作的差异，为上层的操作提供一个统一的接口。正是因为有了这个层次，Linux 中允许众多不同的文件系统共存并且对文件的操作可以跨文件系统而执行。</p><p>VFS 中包含着向物理文件系统转换的一系列数据结构，如 VFS 超级块、VFS 的 inode、各种操作函数的转换入口等。Linux 中 VFS 依靠四个主要的数据结构来描述其结构信息，分别为超级块、索引结点、目录项和文件对象。</p><ol><li>超级块（Super Block）：超级块对象表示一个文件系统。它存储一个已安装的文件系统的控制信息，包括文件系统名称（比如Ext2）、文件系统的大小和状态、块设备的引用和元数据信息（比如空闲列表等等）。VFS超级块存在于内存中，它在文件系统安装时建立，并且在文件系统卸载时自动删除。同时需要注意的是对于每个具体的文件系统来说，也有各自的超级块，它们存放于磁盘。</li><li>索引结点（inode）：索引结点对象存储了文件的相关元数据信息，例如：文件大小、设备标识符、用户标识符、用户组标识符等等。inode 分为两种：一种是 VFS 的 inode，一种是具体文件系统的 inode。前者在内存中，后者在磁盘中。所以每次其实是将磁盘中的 inode调进填充内存中的 inode，这样才是算使用了磁盘文件 inode。当创建一个文件的时候，就给文件分配了一个 inode。一个 inode 只对应一个实际文件，一个文件也会只有一个 inode。</li><li>目录项（Dentry）：引入目录项对象的概念主要是出于方便查找文件的目的。不同于前面的两个对象，目录项对象没有对应的磁盘数据结构，只存在于内存中。一个路径的各个组成部分，不管是目录还是普通的文件，都是一个目录项对象。如，在路径<code>/home/test.java</code>中，目录 /, home, source和文件 test.java 都对应一个目录项对象。VFS 在查找的时候，根据一层一层的目录项找到对应的每个目录项的Inode，那么沿着目录项进行操作就可以找到最终的文件。</li><li>文件对象（File）：文件对象描述的是进程已经打开的文件。因为一个文件可以被多个进程打开，所以一个文件可以存在多个文件对象。一个文件对应的文件对象可能不是惟一的，但是其对应的索引节点和目录项对象肯定是惟一的。</li></ol><p>详细的分析可以参见：<a href="/assets/book/linux/Linux.Virtual.Filesystem.pdf">inux虚拟文件系统</a></p><h3 id="Ext-4-文件系统"><a href="#Ext-4-文件系统" class="headerlink" title="Ext 4 文件系统"></a>Ext 4 文件系统</h3><p>全称 Linux extended file system, extfs，即 Linux 扩展文件系统，Ext2 就代表第二代文件扩展系统，Ext3/Ext4 以此类推，它们都是 Ext2 的升级版，只不过为了快速恢复文件系统，减少一致性检查的时间，增加了日志功能，所以 Ext2 被称为<strong>索引式文件系统</strong>，而 Ext3/Ext4 被称为<strong>日志式文件系统</strong>。</p><blockquote><p> Linux支持很多文件系统，包括网络文件系统(NFS)、Windows的Fat文件系统。  </p></blockquote><p>查看Linux支持的文件系统：<code>ls -l /lib/modules/$(uname -r)/kernel/fs</code></p><pre class=" language-shell"><code class="language-shell">xiehui@xiehui-desktop:~/apps$ ls -l /lib/modules/$(uname -r)/kernel/fs总用量 236drwxr-xr-x 2 root root  4096 4月  24 09:59 9pdrwxr-xr-x 2 root root  4096 4月  24 09:59 adfsdrwxr-xr-x 2 root root  4096 4月  24 09:59 affsdrwxr-xr-x 2 root root  4096 4月  24 09:59 afsdrwxr-xr-x 2 root root  4096 4月  24 09:59 aufsdrwxr-xr-x 2 root root  4096 4月  24 09:59 autofsdrwxr-xr-x 2 root root  4096 4月  24 09:59 befsdrwxr-xr-x 2 root root  4096 4月  24 09:59 bfs........</code></pre><p>查看Linux支持的文件系统(已载入到内存中)：<code>cat /proc/filesystems</code></p><pre class=" language-shell"><code class="language-shell">xiehui@xiehui-desktop:~/apps$ cat /proc/filesystemsnodev    sysfsnodev    rootfsnodev    ramfsnodev    pipefsnodev    hugetlbfsnodev    devpts    ext3    ext2    ext4...</code></pre><p>查看当前机器使用的文件系统类型<code>df -T</code></p><pre class=" language-shell"><code class="language-shell">xiehui@xiehui-desktop:~/apps$ df -T文件系统                    类型         1K-块     已用      可用 已用% 挂载点udev                        devtmpfs   3939508        0   3939508    0% /devtmpfs                       tmpfs       792544     2112    790432    1% /run/dev/mapper/ubuntu--vg-root ext4     243559804 77716804 153401196   34% /</code></pre><h4 id="主要特性"><a href="#主要特性" class="headerlink" title="主要特性"></a>主要特性</h4><p><strong>兼容性(Compatibility)</strong></p><p>Ext4 兼容 Ext3，升级只需运行一些命令即可，不需要变动磁盘格式，升级中不会影响已有的数据。</p><p><strong>更大的文件系统和文件大小(Bigger File System and File Sizes )</strong></p><table><thead><tr><th align="left">File System</th><th align="left">Max FS Size</th><th align="left">Max File Size</th><th align="left">block addressing bits</th></tr></thead><tbody><tr><td align="left">Ext3</td><td align="left">16TB</td><td align="left">2TB</td><td align="left">32</td></tr><tr><td align="left">Ext4</td><td align="left">1EB</td><td align="left">16TB</td><td align="left">48</td></tr></tbody></table><p>​    Tips:</p><ul><li><p>1 EB = 1024 * 1024 TB</p></li><li><p>block size： 4 bytes</p></li></ul><p><strong>拓展子目录数量(Sub directory scalability )</strong></p><p>在一个目录中 :</p><ul><li><p>Ext3 支持 32000 个子目录</p></li><li><p>Ext4 支持 64000 个子目录</p></li></ul><p><strong>拓展块大小(Extents)</strong></p><p>Ext3 为每个文件维护一个 block 表，用于保存这个文件在磁盘上的块号，因为一个 block 只有 4kb 的大小，所以对于一个大文件来说的话，需要维护的 block 表占用的空间就比较可观了，删除和截断等操作的效率也就比较低。</p><p>Ext4 使用 extents 代替 block。 extents 由多个连续的 block 组成。能够有效的减少需要维护的 block 表的长度，进而提高在文件上操作的效率</p><p><strong>多块分配(Multiblock allocation)</strong></p><p>当需要将新数据写入磁盘上时，需要块分配器决定将数据写入哪一个空闲块中。</p><p>但是 Ext3 写入的时候，每次只分配一个 block(4kb), 也就是说如果要写入 100 Mb 的数据时会调用块分配器 25600 词，效率很低，分配器也无法作优化。</p><p>Ext4 使用多块分配器，根据需要，一次调用分配多个块(一个 extents)</p><p><strong>延迟分配(Delayed allocation)</strong></p><p>传统的文件系统尽可能早的分配磁盘 blocks，当进程调用 <code>write()</code> 时，文件系统立即为其分配 block，即使数据并没有立即写入磁盘(在缓存中临时存放)。这种方式的缺点是当进程持续向文件写入数据，文件增长时需要分配另外的 block 来存放新增的数据，块分配器无法对分配方式作优化。</p><p>而延迟分配策略解决了这个问题，当进程调用 <code>write()</code> 时它并不立即分配 blocks，直到数据从缓存写入磁盘时进行分配。写入磁盘时，数据基本就不再增长了，此时使用多块分配器为该文件分配多个 extents</p><p><strong>快速文件系统检测(Fast fsck)</strong></p><p>文件系统检测是一项非常慢的操作，特别是检查文件系统中所有的 inode 节点。</p><p>Ext4 跳过未使用的 inode 节点来加快检测速度，根据已使用的 inode 节点的数量不同，性能会提升 2 到 20 倍。</p><p><strong>日志校验(Journal checksumming)</strong></p><p>使用校验和来判断一个日志块是否已失效。</p><p>Ext3 使用两阶段(执行 + commit/rollback)提交来保证正确性。</p><p>Ext4 使用一阶段提交 + 日志校验来保证正确性，性能提升大约 20%。</p><p><strong>禁用日志模式(“No Journaling” mode )</strong></p><p>日志确保了磁盘上内容变动时文件系统的完整性，但是却带来了少量的额外开销(日志记录)。</p><p>通过禁用日志特性可以获得少量的性能提升</p><p><strong>在线磁盘整理(Online defragmentation )</strong></p><p>这个特性正在开发中，会包含到之后的版本中。</p><p>通过使用延迟分配、extents 和 多块分配能够有效减少磁盘碎片，但是文件内容变动(可以需要另外的 block 来存放数据，这个 block 可能会离原来的地方比较远，从而引发一次额外的寻道)也会带来很多碎片，磁盘碎片整理可以将文件尽可能的重分配到连续的 block 中，从而减少磁盘碎片，提高访问效率。</p><p><strong>Inode 相关特性(Inode-related features)</strong></p><ol><li>更大的 inodes：Ext3 支持配置 inode 大小，默认为 128 bytes，Ext4 默认为 256 bytes。增加了一些额外的域(比如纳秒级的 timestamps 或 inode 版本)，剩余的空间用来保存拓展属性。这种方式可以使访问这些属性的速度更快，从而提高应用程序的性能。</li><li>当创建目录时，直接为其创建几个保留的 inode 节点，当在这个目录中创建新文件时，就可以直接使用这些保留的 inode 节点，从而提高文件创建和删除的效率。</li><li>Ext3 的时间属性是秒级的，Ext4 的时间属性是纳秒级的。</li></ol><p><strong>磁盘预分配(Persistent preallocation )</strong></p><p>这个特性允许应用程序预先分配磁盘空间，应用通知文件系统预先分配空间，文件系统预先分配需要的块和数据结构，直到应用程序向该空间写数据前，该空间中是没有数据的。</p><p><strong>屏障默认开启(Barriers on by default)</strong></p><p>这个选项改善了文件系统的完整性，但损失了一些性能。</p><p>文件系统在写入数据之前必须先将事务信息记录到日志，然后根据顺序写入，但是这种方式效率比较低。现代的驱动有很大的内部缓存并且为了得到更好的性能会进行操作重排序，所以在写入数据之前，文件系统必须先显式的指示磁盘加载所有的日志。</p><p>内核的 阻塞 I/O 子系统使用屏障来实现，即在加载日志时进行阻塞，其他数据 I/O 操作就无法再进行了。</p><h3 id="通用块层"><a href="#通用块层" class="headerlink" title="通用块层"></a>通用块层</h3><img src="/images/2015/disk_35.png"><p>通用块层的主要工作是：接收上层发出的磁盘请求，并最终发出 I/O 请求。该层隐藏了底层硬件块设备的特性，为块设备提供了一个通用的抽象视图。</p><p>对于 VFS 和具体的文件系统来说，块（Block）是基本的数据传输单元，当内核访问文件的数据时，它首先从磁盘上读取一个块。但是对于磁盘来说，扇区是最小的可寻址单元，块设备无法对比它还小的单元进行寻址和操作。由于扇区是磁盘的最小可寻址单元，所以块不能比扇区还小，只能整数倍于扇区大小，即一个块对应磁盘上的一个或多个扇区。一般来说，块大小是2的整数倍，而且由于 Page Cache 层的最小单元是页（Page），所以块大小不能超过一页的长度。</p><p>大多情况下，数据的传输通过 DMA 方式。旧的磁盘控制器，仅仅支持简单的 DMA 操作：每次数据传输，只能传输磁盘上相邻的扇区，即数据在内存中也是连续的。这是因为如果传输非连续的扇区，会导致磁盘花费更多的时间在寻址操作上。而现在的磁盘控制器支持“分散/聚合”DMA操作，这种模式下，数据传输可以在多个非连续的内存区域中进行。为了利用“分散/聚合”DMA操作，块设备驱动必须能处理被称为段（segments）的数据单元。一个段就是一个内存页面或一个页面的部分，它包含磁盘上相邻扇区的数据。</p><p>通用块层是粘合所有上层和底层的部分，一个页的磁盘数据布局如下图所示：</p><img src="/images/2015/1.jpeg"><p>详细的分析可以参见：<a href="/assets/book/linux/Linux.Generic.Block.Layer.pdf">Linux通用块设备层</a></p><h3 id="I-O调度层"><a href="#I-O调度层" class="headerlink" title="I/O调度层"></a>I/O调度层</h3><p>I/O调度层的功能是管理块设备的请求队列。即接收通用块层发出的I/O请求，缓存请求并试图合并相邻的请求。并根据设置好的调度算法，回调驱动层提供的请求处理函数，以处理具体的 I/O 请求。</p><p>如果简单地以内核产生请求的次序直接将请求发给块设备的话，那么块设备性能肯定让人难以接受，因为磁盘寻址是整个计算机中最慢的操作之一。为了优化寻址操作，内核不会一旦接收到 I/O 请求后，就按照请求的次序发起块 I/O 请求。为此 Linux 实现了几种 I/O 调度算法，算法基本思想就是通过合并和排序 I/O 请求队列中的请求，以此大大降低所需的磁盘寻道时间，从而提高整体I/O性能。</p><p>常见的 I/O 调度算法包括 Noop 调度算法（No Operation）、CFQ（完全公正排队I/O调度算法）、DeadLine（截止时间调度算法）、AS 预测调度算法等。</p><ul><li>Noop 算法：最简单的 I/O 调度算法。该算法仅适当合并用户请求，并不排序请求。新的请求通常被插在调度队列的开头或末尾，下一个要处理的请求总是队列中的第一个请求。这种算法是为不需要寻道的块设备设计的，如 SSD。因为其他三个算法的优化是基于缩短寻道时间的，而 SSD 硬盘没有所谓的寻道时间且I/O响应时间非常短。</li><li>CFQ 算法：算法的主要目标是在触发 I/O 请求的所有进程中确保磁盘 I/O 带宽的公平分配。算法使用许多个排序队列，存放了不同进程发出的请求。通过散列将同一个进程发出的请求插入同一个队列中。采用轮询方式扫描队列，从第一个非空队列开始，依次调度不同队列中特定个数（公平）的请求，然后将这些请求移动到调度队列的末尾。</li><li>Deadline 算法：算法引入了两个排队队列分别包含读请求和写请求，两个最后期限队列包含相同的读和写请求。本质就是一个超时定时器，当请求被传给电梯算法时开始计时。一旦最后期限队列中的超时时间已到，就想请求移至调度队列末尾。Deadline算法避免了电梯调度策略（为了减少寻道时间，会优先处理与上一个请求相近的请求）带来的对某个请求忽略很长一段时间的可能。</li><li>AS 算法：AS 算法本质上依据局部性原理，预测进程发出的读请求与刚被调度的请求在磁盘上可能是“近邻”。算法统计每个进程 I/O 操作信息，当刚刚调度了由某个进程的一个读请求之后，算法马上检查排序队列中的下一个请求是否来自同一个进程。如果是，立即调度下一个请求。否则，查看关于该进程的统计信息，如果确定进程p可能很快发出另一个读请求，那么就延迟一小段时间。</li></ul><p>前文中计算出的 IOPS 是理论上的随机读写的最大 IOPS，在随机读写中，每次 I/O 操作的寻址和旋转延时都不能忽略不计，有了这两个时间的存在也就限制了 IOPS 的大小。现在如果我们考虑在读取一个很大的存储连续分布在磁盘的文件，因为文件的存储的分布是连续的，磁头在完成一个读 I/O 操作之后，不需要重新寻址，也不需要旋转延时，在这种情况下我们能到一个很大的 IOPS 值。这时由于不再考虑寻址和旋转延时，则性能瓶颈仅是数据传输时延，假设数据传输时延为0.4ms，那么IOPS=1000 / 0.4 = 2500 IOPS。</p><p>在许多的开源框架如 Kafka、HBase中，都通过追加写的方式来尽可能的将随机 I/O 转换为顺序 I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高 IOPS。</p><p>详细的分析可以参见：<a href="/assets/book/linux/Linux.Kernel.IO.Scheduler.pdf">Linux内核IO调度层</a></p><h3 id="块设备驱动层"><a href="#块设备驱动层" class="headerlink" title="块设备驱动层"></a>块设备驱动层</h3><p>驱动层中的驱动程序对应具体的物理块设备。它从上层中取出I/O请求，并根据该I/O请求中指定的信息，通过向具体块设备的设备控制器发送命令的方式，来操纵设备传输数据。</p><h2 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h2><h3 id="open"><a href="#open" class="headerlink" title="open"></a>open</h3><p><code>open</code> 负责在内核生成与文件相对应的<code>struct file</code>元数据结构，并且与文件系统中该文件的<code>struct inode</code>进行关联，装载对应文件系统的操作回调函数，然后返回一个<code>int fd</code>给用户进程。后续用户对该文件的相关操作，会涉及到其相关的<code>struct file</code>、<code>struct inode</code>、<code>inode-&gt;i_op</code>、<code>inode-&gt;i_fop</code>和<code>inode-&gt;i_mapping-&gt;a_ops</code>等。</p><blockquote><p>文件操作对应的偏移存储于struct file中，每个open的文件单独维护一份，同一个文件的读写操作共享同一个偏移。</p></blockquote><p>其整个内核逻辑流程可以用下图来表示：</p><img src="/images/2015/disk_36.png"><h3 id="write"><a href="#write" class="headerlink" title="write"></a>write</h3><p><code>write</code>的写逻辑路径有好几条，最常使用的就是利用<code>pagecache</code>延迟写的这条路径，所以主要分析这个。在<code>write</code>调用的调用、返回之间，其负责分配新的<code>pagecache</code>，将数据写入<code>pagecache</code>，同时根据系统参数，判断<code>pagecache</code>中的脏数据占比来确定是否要触发回写逻辑。其详细的代码分析可以参考：<a href="/assets/book/linux/Linux.Kernel.Write.Procedure.pdf">《Linux内核写文件过程》</a>和<a href="/assets/book/linux/Linux.Kernel.Delay.Write.pdf">《Linux内核延迟写机制》</a>。</p><p>其整个内核逻辑流程可以用下图来表示：</p><img src="/images/2015/disk_37.png"><h3 id="read"><a href="#read" class="headerlink" title="read"></a>read</h3><p><code>read</code>的读逻辑中包含预期<code>readahead</code>的逻辑，其可以通过与<code>fadvise</code>的配合达到文件预取的效果。这部分的代码分析可以参考：<a href="/assets/book/linux/Linux.Kernel.Read.Procedure.pdf">《Linux内核读文件过程》</a></p><p>其整个内核逻辑流程可以用下图来表示：</p><img src="/images/2015/disk_38.png"><h3 id="fsync-fdatasync"><a href="#fsync-fdatasync" class="headerlink" title="fsync/fdatasync"></a>fsync/fdatasync</h3><p><code>fsync</code>和<code>fdatasync</code>主要逻辑流程基本相同。其通过触发对应文件的<code>pagecache</code>脏页回写，并且阻塞等待到回写逻辑完成，以达到同步数据的目的。</p><p>其整个内核逻辑流程可以用下图来表示：</p><img src="/images/2015/disk_39.png"><h3 id="mmap"><a href="#mmap" class="headerlink" title="mmap"></a>mmap</h3><p>用户调用<code>mmap</code>将文件映射到内存时，内核进行一系列的参数检查，然后创建对应的<code>vma</code>，然后给该<code>vma</code>绑定<code>vma_ops</code>。当用户访问到<code>mmap</code>对应的内存时，CPU会触发<code>page fault</code>，在<code>page fault</code>回调中，将申请<code>pagecache</code>中的匿名页，读取文件到其物理内存中，然后将<code>pagecache</code>中所属的物理页与用户进程的<code>vma</code>进行映射。</p><p>其整个内核逻辑流程可以用下图来表示，其中<code>page fault</code>部分比较简略，可以参考<a href="/assets/book/linux/linux-page-fault/">Linux Page Fault(缺页异常)</a>： </p><img src="/images/2015/disk_40.png"><h3 id="munmap"><a href="#munmap" class="headerlink" title="munmap"></a>munmap</h3><img src="/images/2015/disk_41.png"><h3 id="msync"><a href="#msync" class="headerlink" title="msync"></a>msync</h3><p><code>msync</code>的实际实现与其手册中的描述有很大不同，其调用时，<code>flag=MS_SYNC</code>等同于对<code>mmap</code>对应的文件调用<code>fsync</code>；<code>flag=MS_ASYNC/MS_INVALIDATE</code>其实什么都不执行。</p><img src="/images/2015/disk_42.png"><h3 id="madvise"><a href="#madvise" class="headerlink" title="madvise"></a>madvise</h3><img src="/images/2015/disk_43.png"><h3 id="fadvise-1"><a href="#fadvise-1" class="headerlink" title="fadvise"></a>fadvise</h3><img src="/images/2015/disk_44.png"><h2 id="编程实践"><a href="#编程实践" class="headerlink" title="编程实践"></a>编程实践</h2><h3 id="File-IO"><a href="#File-IO" class="headerlink" title="File IO"></a>File IO</h3><p><code>java.io</code> 包下的 <code>FileReader</code>、 <code>FileWriter</code> 之类 API ，性能太差基本不考虑使用。</p><h3 id="FileChannel"><a href="#FileChannel" class="headerlink" title="FileChannel"></a>FileChannel</h3><p>FileChannel 采用了 ByteBuffer 内存缓冲区，让我们可以非常精准的控制写盘的大小，这是普通 IO 无法实现的。我们在写入时注意控制 ByteBuffer 的大小，FileChannel 只有在一次写入 4kb 的整数倍时，才能发挥出实际的性能，主要取决你机器的磁盘结构，并且受到操作系统，文件系统，CPU 的影响，需要对使用的机器进行测试获取到最佳写入大小。</p><img src="/images/2015/disk_45.png"><p>FIleChannel <code>write</code> 和 <code>read</code> 方法均是<strong>线程安全</strong>的，FileChannel 内部通过一把 <code>private final Object positionLock = new Object();</code> 锁来控制并发。</p><pre class=" language-java"><code class="language-java"><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>FileInputStream<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>FileOutputStream<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>ByteBuffer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>FileChannel<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestFileChannel</span> <span class="token punctuation">{</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        FileInputStream inputStream <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileInputStream</span><span class="token punctuation">(</span><span class="token string">"/home/xiehui/test.in"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileChannel in <span class="token operator">=</span> inputStream<span class="token punctuation">.</span><span class="token function">getChannel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileOutputStream outputStream <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FileOutputStream</span><span class="token punctuation">(</span><span class="token string">"/home/xiehui/test.out"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        FileChannel out <span class="token operator">=</span> outputStream<span class="token punctuation">.</span><span class="token function">getChannel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        ByteBuffer buffer <span class="token operator">=</span> ByteBuffer<span class="token punctuation">.</span><span class="token function">allocate</span><span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">/**         * long position = 1024L;         * 指定 position 读取 4kb 的数据         * fileChannel.read(buffer,position)；         * 从当前文件指针的位置读取 4kb 的数据         * fileChannel.read(buffer);         */</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>in<span class="token punctuation">.</span><span class="token function">read</span><span class="token punctuation">(</span>buffer<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            buffer<span class="token punctuation">.</span><span class="token function">flip</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">/**             * byte[] data = new byte[4096];             * long position = 1024L;             * 指定 position 写入 4kb 的数据             * fileChannel.write(ByteBuffer.wrap(data), position);             * 从当前文件指针的位置写入 4kb 的数据             * fileChannel.write(ByteBuffer.wrap(data));             */</span>            out<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>buffer<span class="token punctuation">)</span><span class="token punctuation">;</span>            buffer<span class="token punctuation">.</span><span class="token function">clear</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        out<span class="token punctuation">.</span><span class="token function">force</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">//将文件数据和元数据强制写到磁盘上</span>        inputStream<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        outputStream<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><h3 id="MMAP"><a href="#MMAP" class="headerlink" title="MMAP"></a>MMAP</h3><p>从代码层面上看，从硬盘上将文件读入内存，都要经过文件系统进行数据拷贝，并且数据拷贝操作是由文件系统和硬件驱动实现的，理论上来说，拷贝数据的效率是一样的。但是通过内存映射的方法访问硬盘上的文件，效率要比read和write系统调用高，原因是：</p><p><code>read()</code>是系统调用，首先将文件从硬盘拷贝到内核空间的一个缓冲区，再将这些数据拷贝到用户空间，实际上进行了两次数据拷贝；</p><p><code>map()</code>也是系统调用，<strong>但没有进行数据拷贝，当缺页中断发生时，直接将文件从硬盘拷贝到用户空间，只进行了一次数据拷贝</strong>。</p><p>所以，<strong>理论</strong>上采用内存映射的读写效率要比传统的<code>read/write</code>性能高。</p><p><strong>优缺点</strong>：</p><ol><li><p>MMAP 使用虚拟内存，因此分配(map)的内存大小不受JVM的-Xmx参数限制，但是也是有大小限制的。MMAP 使用时必须实现指定好内存映射的大小，并且一次 map 的大小限制在 1.5G 左右，重复 map 又会带来虚拟内存的回收、重新分配的问题，对于文件不确定大小的情形不太友好。</p></li><li><p>如果当文件超出1.5G限制时，可以通过 position 参数重新 map 文件后面的内容；</p></li><li><p>MMAP 使用的是虚拟内存，和 PageCache 一样是由操作系统来控制刷盘的，虽然可以通过 <code>force()</code> 来手动控制，但这个时间把握不好，在小内存场景下会很令人头疼。</p></li><li><p>MMAP 的回收问题，当 MappedByteBuffer 不再需要时，可以手动释放占用的虚拟内存，注意 JDK 不同版本的区别。</p></li></ol><p>MMAP 在实际使用中并没有表现出比 FileChannel 优异的性能。建议<strong>优先使用 FileChannel</strong>。</p><pre class=" language-java"><code class="language-java"><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>File<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>FileOutputStream<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>io<span class="token punctuation">.</span>RandomAccessFile<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>reflect<span class="token punctuation">.</span>Method<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>ByteBuffer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>MappedByteBuffer<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>nio<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>FileChannel<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>security<span class="token punctuation">.</span>AccessController<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>security<span class="token punctuation">.</span>PrivilegedAction<span class="token punctuation">;</span><span class="token keyword">import</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span>reflect<span class="token punctuation">.</span>Field<span class="token punctuation">;</span><span class="token keyword">import</span> sun<span class="token punctuation">.</span>misc<span class="token punctuation">.</span>Unsafe<span class="token punctuation">;</span><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">TestMMAP</span> <span class="token punctuation">{</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">int</span> count <span class="token operator">=</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">1024</span> <span class="token operator">*</span> <span class="token number">1024</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// 1G</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">final</span> Unsafe UNSAFE<span class="token punctuation">;</span>        <span class="token keyword">static</span> <span class="token punctuation">{</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>            Field field <span class="token operator">=</span> Unsafe<span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">.</span><span class="token function">getDeclaredField</span><span class="token punctuation">(</span><span class="token string">"theUnsafe"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            field<span class="token punctuation">.</span><span class="token function">setAccessible</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            UNSAFE <span class="token operator">=</span> <span class="token punctuation">(</span>Unsafe<span class="token punctuation">)</span> field<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>null<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">RuntimeException</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> Exception <span class="token punctuation">{</span>        File f <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">File</span><span class="token punctuation">(</span><span class="token string">"/home/xiehui/largeFile.txt"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        RandomAccessFile rf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">RandomAccessFile</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> <span class="token string">"rw"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// Mapping a file into memory</span>        MappedByteBuffer out <span class="token operator">=</span> rf<span class="token punctuation">.</span><span class="token function">getChannel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>FileChannel<span class="token punctuation">.</span>MapMode<span class="token punctuation">.</span>READ_WRITE<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> count<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// Writing into Memory Mapped File</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> count<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            out<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">byte</span><span class="token punctuation">)</span> <span class="token string">'A'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Writing to Memory Mapped File is completed"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">// reading from memory file in Java</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">char</span><span class="token punctuation">)</span> out<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        System<span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"Reading from Memory Mapped File is completed"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        rf<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        UNSAFE<span class="token punctuation">.</span><span class="token function">invokeCleaner</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">// >= jdk 9 采用这个方法 unmap</span>        <span class="token comment" spellcheck="true">//clean(out); // &lt; jdk 9 采用这个方法</span>    <span class="token punctuation">}</span>    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">clean</span><span class="token punctuation">(</span>MappedByteBuffer mappedByteBuffer<span class="token punctuation">)</span> <span class="token punctuation">{</span>        ByteBuffer buffer <span class="token operator">=</span> mappedByteBuffer<span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>buffer <span class="token operator">==</span> null <span class="token operator">||</span> <span class="token operator">!</span>buffer<span class="token punctuation">.</span><span class="token function">isDirect</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">||</span> buffer<span class="token punctuation">.</span><span class="token function">capacity</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>            <span class="token keyword">return</span><span class="token punctuation">;</span>        <span class="token function">invoke</span><span class="token punctuation">(</span><span class="token function">invoke</span><span class="token punctuation">(</span><span class="token function">viewed</span><span class="token punctuation">(</span>buffer<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"cleaner"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"clean"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">/**     * 在MappedByteBuffer释放后再对它进行读操作的话就会引发 jvm crash，在并发情况下很容易发生     * 正在释放时另一个线程正开始读取，于是 crash 就发生了。所以为了系统稳定性释放前一般需要检查是否还有线程在读或写     * @param target     * @param methodName     * @param args     * @return     */</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> Object <span class="token function">invoke</span><span class="token punctuation">(</span><span class="token keyword">final</span> Object target<span class="token punctuation">,</span> <span class="token keyword">final</span> String methodName<span class="token punctuation">,</span> <span class="token keyword">final</span> Class<span class="token operator">&lt;</span><span class="token operator">?</span><span class="token operator">></span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> AccessController<span class="token punctuation">.</span><span class="token function">doPrivileged</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">PrivilegedAction</span><span class="token operator">&lt;</span>Object<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">public</span> Object <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token keyword">try</span> <span class="token punctuation">{</span>                    Method method <span class="token operator">=</span> <span class="token function">method</span><span class="token punctuation">(</span>target<span class="token punctuation">,</span> methodName<span class="token punctuation">,</span> args<span class="token punctuation">)</span><span class="token punctuation">;</span>                    method<span class="token punctuation">.</span><span class="token function">setAccessible</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token keyword">return</span> method<span class="token punctuation">.</span><span class="token function">invoke</span><span class="token punctuation">(</span>target<span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>                    <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">IllegalStateException</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> Method <span class="token function">method</span><span class="token punctuation">(</span>Object target<span class="token punctuation">,</span> String methodName<span class="token punctuation">,</span> Class<span class="token operator">&lt;</span><span class="token operator">?</span><span class="token operator">></span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> NoSuchMethodException <span class="token punctuation">{</span>        <span class="token keyword">try</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> target<span class="token punctuation">.</span><span class="token function">getClass</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getMethod</span><span class="token punctuation">(</span>methodName<span class="token punctuation">,</span> args<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">NoSuchMethodException</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> target<span class="token punctuation">.</span><span class="token function">getClass</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getDeclaredMethod</span><span class="token punctuation">(</span>methodName<span class="token punctuation">,</span> args<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">private</span> <span class="token keyword">static</span> ByteBuffer <span class="token function">viewed</span><span class="token punctuation">(</span>ByteBuffer buffer<span class="token punctuation">)</span> <span class="token punctuation">{</span>        String methodName <span class="token operator">=</span> <span class="token string">"viewedBuffer"</span><span class="token punctuation">;</span>        Method<span class="token punctuation">[</span><span class="token punctuation">]</span> methods <span class="token operator">=</span> buffer<span class="token punctuation">.</span><span class="token function">getClass</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getMethods</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> methods<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>methods<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">getName</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token string">"attachment"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                methodName <span class="token operator">=</span> <span class="token string">"attachment"</span><span class="token punctuation">;</span>                <span class="token keyword">break</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        ByteBuffer viewedBuffer <span class="token operator">=</span> <span class="token punctuation">(</span>ByteBuffer<span class="token punctuation">)</span> <span class="token function">invoke</span><span class="token punctuation">(</span>buffer<span class="token punctuation">,</span> methodName<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>viewedBuffer <span class="token operator">==</span> null<span class="token punctuation">)</span>            <span class="token keyword">return</span> buffer<span class="token punctuation">;</span>        <span class="token keyword">else</span>            <span class="token keyword">return</span> <span class="token function">viewed</span><span class="token punctuation">(</span>viewedBuffer<span class="token punctuation">)</span><span class="token punctuation">;</span>       <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>可以参考 kafka 的工具类<a href="https://github.com/apache/kafka/blob/e554dc518eaaa0747899e708160275f95c4e525f/clients/src/main/java/org/apache/kafka/common/utils/MappedByteBuffers.java" target="_blank" rel="noopener">MappedByteBuffers</a>的实现方式。</p><h3 id="Direct-IO"><a href="#Direct-IO" class="headerlink" title="Direct IO"></a>Direct IO</h3><p>Java 中常用的文件操作接口为：FileChannel，并且没有直接操作 Direct IO 的接口。这也就意味着 Java 无法绕开 PageCache 直接对存储设备进行读写，但对于使用 Java 语言来编写的数据库，消息队列等产品而言，的确存在绕开 PageCache 的需求：</p><ul><li>PageCache 属于操作系统层面的概念，用户层面很难干预，User BufferCache 显然比 Kernel PageCache 要可控</li><li>现代操作系统会使用尽可能多的空闲内存来充当 PageCache，当操作系统回收 PageCache 内存的速度低于应用写缓存的速度时，会影响磁盘写入的速率，直接表现为写入 RT 增大，这被称之为“毛刺现象”</li></ul><p>PageCache 可能会好心办坏事，采用 Direct IO + 自定义内存管理机制会使得产品更加的可控，高性能。</p><p><strong>Direct IO 的限制</strong></p><p>在 Java 中使用 Direct IO 最终需要调用到 c 语言的 pwrite 接口，并设置 O_DIRECT flag，使用 O_DIRECT 存在不少限制:</p><ul><li>操作系统限制：Linux 操作系统在 2.4.10 及以后的版本中支持 O_DIRECT flag，老版本会忽略该 Flag；Mac OS 也有类似于 O_DIRECT 的机制</li><li>用于传递数据的缓冲区，其内存边界必须对齐为 blockSize 的整数倍</li><li>用于传递数据的缓冲区，其传递数据的大小必须是 blockSize 的整数倍。</li><li>数据传输的开始点，即文件和设备的偏移量，必须是 blockSize 的整数倍</li></ul><p>如果想在 Java 中使用 Direct IO  可以参考项目 <a href="https://github.com/lexburner/kdio" target="_blank" rel="noopener">https://github.com/lexburner/kdio</a> </p><h2 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h2><p>本文对文件 IO 的知识进行了全面的梳理和整理，为后续在实现存储类项目时提供参考。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://www.ssdfans.com/blog/2018/05/17/从sata、sas到nvme-ssd/" target="_blank" rel="noopener">从SATA、SAS到NVMe SSD</a></p><p><a href="http://www.ssdfans.com/?p=131" target="_blank" rel="noopener">SSD背后的秘密：SSD基本工作原理</a></p><p><a href="http://www.jinbuguo.com/storage/ssd_intro.html" target="_blank" rel="noopener">SSD(固态硬盘)简介</a></p><p><a href="https://www.infoq.cn/article/pWEW6yTk_9QrAUp4EH85" target="_blank" rel="noopener">NVMe SSD 性能影响因素</a></p><p><a href="https://www.cnblogs.com/zengkefu/p/6372148.html" target="_blank" rel="noopener">如何提高Linux下块设备IO的整体性能？</a></p><p> <a href="https://tech.meituan.com/2017/05/19/about-desk-io.html" target="_blank" rel="noopener">磁盘I/O那些事</a></p><p><a href="http://blog.yufeng.info/archives/1917" target="_blank" rel="noopener">posix_fadvise清除缓存的误解和改进措施</a></p><p><a href="https://www.ibm.com/developerworks/cn/linux/l-vfs/index.html" target="_blank" rel="noopener">解析 Linux 中的 VFS 文件系统机制</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> IO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/05/19/hello-world/"/>
      <url>/2020/05/19/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
